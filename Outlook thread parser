"""
Enhanced Mail Harvester with Email Thread Parsing
Integrates thread detection without changing existing flow
"""

import re
import gc
import logging
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


# ============================================================================
# EMAIL THREAD PARSER (NEW)
# ============================================================================

class EmailThreadParser:
    """Extract only latest message from threaded emails"""
    
    THREAD_SEPARATORS = [
        r'^-+\s*Original Message\s*-+',
        r'^_+\s*From:\s*.+\nSent:\s*.+',
        r'^On\s+.+?wrote:',
        r'^\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\s+.+?<.+?>.*:',
        r'^------+\s*Forwarded message',
        r'------+\s*End Forwarded Message',
        r'^From:.*?Sent:.*?To:',
    ]
    
    @staticmethod
    def extract_latest_message(body: str) -> Dict:
        """Extract only the latest message from thread"""
        result = {
            'latest_message': body if body else '',
            'is_threaded': False,
            'thread_count': 1
        }
        
        if not body or not body.strip():
            return result
        
        earliest_separator_pos = len(body)
        
        for separator_pattern in EmailThreadParser.THREAD_SEPARATORS:
            match = re.search(separator_pattern, body, re.MULTILINE | re.IGNORECASE)
            if match and match.start() < earliest_separator_pos:
                earliest_separator_pos = match.start()
        
        if earliest_separator_pos < len(body):
            result['is_threaded'] = True
            result['latest_message'] = body[:earliest_separator_pos].strip()
            result['thread_count'] = len(re.findall(
                r'(On\s+.+?wrote:|From:.*?Sent:|^-+\s*Original Message)',
                body,
                re.MULTILINE | re.IGNORECASE
            )) + 1
        else:
            result['latest_message'] = body.strip()
        
        return result


# ============================================================================
# MAIN MAIL HARVESTER CLASS (UPDATED)
# ============================================================================

def extract_email_chain_from_outlook(self):
    """Modified to use thread parser"""
    trade_ids_str = None
    df = pd.DataFrame(columns=self.selected_columns)
    
    if hasattr(self, "trade_ids_var") or isinstance(self.trade_ids_var, tk.StringVar):
        trade_ids_str = self.trade_ids_var.get().strip()
    
    if not trade_ids_str:
        file_path = self.file_path_var.get().strip()
        if not file_path or not os.path.exists(file_path):
            messagebox.showwarning("Input Error", "Please upload a valid file/input trade_id")
            return
        self.trade_ids_var.set(self.process_trade_file(file_path))
        trade_ids_str = self.trade_ids_var.get().strip()
    
    trade_ids = [tid.strip() for tid in re.split(",|\\s+", trade_ids_str) if tid.strip()]
    logger.info(f"Input TradeIds: {trade_ids}")
    
    self.progress.start()
    self.clear_results()
    self.emails = []
    self.unfound_trades = []
    
    def worker():
        error_msg = None  # â† INITIALIZE ERROR VARIABLE HERE
        
        pythoncom.CoInitialize()
        try:
            folder = self.connect_to_outlook()
            if not folder:
                self.root.after(0, lambda: self.finish_extraction([], "Could not connect to folder"))
                return
            
            today = datetime.now() + timedelta(days=-1)
            today = datetime.strptime(self.date_var.get(), "%Y-%m-%d") + timedelta(days=-1)
            
            days_back = 2
            checked_days = 0
            days_ago = 1
            date_fmt, use_ampm = self.get_region_dateformat_ampm()
            
            logger.info(f"Detected locale dateformat: {date_fmt}, Use AM/PM: {use_ampm}")
            all_items = []
            
            while checked_days < days_back:
                d = today - timedelta(days=days_ago)
                days_ago += 1
                
                if d.weekday() >= 5:
                    continue
                
                checked_days += 1
                start_time, end_time = self.restrict_datetime_strings(d, date_fmt, use_ampm)
                filter_str = f"[ReceivedTime] >= '{start_time}' AND [ReceivedTime] <= '{end_time}'"
                
                logger.info(f"Trying filter: {filter_str}")
                
                items = folder.Items.Restrict(filter_str)
                items_list = self.process_items_in_batches(items, batch_size=150)
                
                if items_list and use_ampm:
                    pm_l = d.replace(hour=13).strftime('%p').lower()
                    pm_l_alt = d.replace(hour=13).strftime('%p').lower()
                    start_time_l = f"{d.strftime(date_fmt)} 12:00:00 {am_l}"
                    end_time_l = f"{d.strftime(date_fmt)} 11:59:59 {pm_l}"
                    filter_str_l = f"[ReceivedTime] >= '{start_time_l}' AND [ReceivedTime] <= '{end_time_l}'"
                    logger.info(f"Trying filter (lowercase): {filter_str_l}")
                    items = folder.Items.Restrict(filter_str_l)
                    items_list = self.process_items_in_batches(items, batch_size=150)
                
                if items_list:
                    logger.info(f"Found {len(items_list)} emails for {d.strftime(date_fmt)}")
                    all_items.extend([entry["items"] for entry in items_list])
                else:
                    logger.info(f"No emails for {d.strftime(date_fmt)}")
            
            # =============== CRITICAL: GROUP & SORT BY TRADE ID ===============
            tid_re = re.compile("|".join(re.escape(tid) for tid in trade_ids), re.IGNORECASE)
            matches_by_tradeid = {tid: [] for tid in trade_ids}
            all_emails = []
            
            for item in all_items:
                try:
                    if getattr(item, "Class", None) == 43:
                        subject = item.Subject or ""
                        body = item.Body or ""
                        html_body = ""
                        try:
                            html_body = item.HTMLBody
                        except Exception:
                            pass
                        
                        search_zone = f"{subject}\n{body}\n{html_body}"
                        found_tids = set(m.lower() for m in tid_re.findall(search_zone))
                        
                        for orig_tid in trade_ids:
                            if orig_tid.lower() in found_tids:
                                # ============ THREAD PARSING ============
                                thread_info = self.thread_parser.extract_latest_message(body)
                                
                                email_obj = {
                                    'trade_id': orig_tid,
                                    'subject': subject,
                                    'sender': getattr(item, "SenderName", ""),
                                    'recipient': getattr(item, "To", ""),
                                    'date': item.ReceivedTime.strftime("%Y-%m-%d %H:%M:%S") if item.ReceivedTime else "",
                                    'body': thread_info['latest_message'],  # â† LATEST ONLY
                                    'is_threaded': thread_info['is_threaded'],
                                    'thread_count': thread_info['thread_count'],
                                    'raw_body': body
                                }
                                
                                matches_by_tradeid[orig_tid].append(email_obj)
                                all_emails.append(email_obj)
                
                except Exception as item_error:  # â† CAPTURE IN INNER TRY
                    logger.warning(f"Error processing item: {str(item_error)}")
                    pass
            
            gc.collect()
            
            # Sort each trade's emails by date (newest first)
            for trade_id in sorted(matches_by_tradeid.keys()):
                matches_by_tradeid[trade_id].sort(
                    key=lambda x: parser.parse(x['date']) if x['date'] else datetime.min,
                    reverse=True
                )
            
            # Rebuild self.emails in sorted order
            self.emails = []
            for trade_id in sorted(matches_by_tradeid.keys()):
                self.emails.append({"trade_id": trade_id, "emails": matches_by_tradeid[trade_id]})
            
            # Highlight for latest emails
            self.tree.tag_configure('latest', background='#99ee99')
            
            # Populate Treeview
            idx = 0
            for entry in self.emails:
                trade_emails = entry['emails']
                for email_idx, mail in enumerate(trade_emails):
                    if email_idx == 0:
                        mail_type = "Latest"
                    else:
                        subj = mail['subject'].lower()
                        if "re:" in subj or "re :" in subj:
                            mail_type = f"Reply ({email_idx})"
                        elif "fw:" in subj or "fwd:" in subj:
                            mail_type = f"Forward ({email_idx})"
                        else:
                            mail_type = f"Email ({email_idx})"
                    
                    if mail_type == "Latest":
                        self.tree.insert('', 'end', iid=str(idx), tags='latest', values=(
                            mail['trade_id'],
                            mail['subject'][:30] + "..." if len(mail['subject']) > 30 else mail['subject'],
                            mail['sender'][:20] + "..." if len(mail['sender']) > 20 else mail['sender'],
                            mail['recipient'][:20] + "..." if len(mail['recipient']) > 20 else mail['recipient'],
                            mail_type,
                            f"{'ğŸ§µ' if mail['is_threaded'] else 'ğŸ“§'} {mail['thread_count']}"
                        ))
                    else:
                        self.tree.insert('', 'end', iid=str(idx), values=(
                            mail['trade_id'],
                            mail['subject'][:30] + "..." if len(mail['subject']) > 30 else mail['subject'],
                            mail['sender'][:20] + "..." if len(mail['sender']) > 20 else mail['sender'],
                            mail['recipient'][:20] + "..." if len(mail['recipient']) > 20 else mail['recipient'],
                            mail_type,
                            f"{'ğŸ§µ' if mail['is_threaded'] else 'ğŸ“§'} {mail['thread_count']}"
                        ))
                    idx += 1
            
            found_trade_ids = set(mail['trade_id'] for mail in all_emails)
            if self.unfound_trades:
                for tid in self.unfound_trades:
                    tid_from_list = [t for t in trade_ids if t.lower() == tid.lower()]
                    if tid_from_list:
                        self.unfound_trades.append(tid_from_list[0])
            
            logger.info(f"Unfound TradeIds: {self.unfound_trades} - Not Found In Email")
            
            for tid in self.unfound_trades:
                filename = f"{tid}_email_entities_export_{datetime.now().strftime('%m_%d_%Y')}.csv"
                out_file = os.path.join(self.temp_path, filename)
                df.to_csv(out_file, index=False)
            
            # SUCCESS - finish extraction
            self.root.after(0, lambda: self.finish_extraction(all_emails, None))
        
        except Exception as e:
            # â† OUTER TRY-EXCEPT NOW CATCHES ALL
            error_msg = str(e)
            logger.error(f"Error in extraction: {error_msg}")
            gc.collect()
            
            # â† USE error_msg VARIABLE (NOT e IN LAMBDA)
            self.root.after(0, lambda msg=error_msg: self.finish_extraction([], msg))
    
    threading.Thread(target=worker, daemon=True).start()


+++++++++++++++++++++++++++++++++++++++++++++++++++++
email fix:

"""
Enhanced Email Thread Parser - Extracts ONLY Current Message
Removes all previous conversations from the same thread
"""

import re
import logging
from typing import Dict

logger = logging.getLogger(__name__)


class AdvancedEmailThreadParser:
    """
    Extract ONLY the current message body, completely removing all previous conversations
    
    Email Structure:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CURRENT MESSAGE (Extract)  â”‚ â† WE WANT THIS ONLY
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ -----Original Message-----  â”‚ â† REMOVE EVERYTHING BELOW
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  PREVIOUS REPLY 2           â”‚ â† REMOVE
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  PREVIOUS REPLY 1           â”‚ â† REMOVE
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  ORIGINAL MESSAGE           â”‚ â† REMOVE
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    
    # More aggressive separators - catches ALL thread markers
    THREAD_SEPARATORS = [
        # Outlook separators (most common)
        (r'^-{5,}\s*Original Message\s*-{5,}', 'OUTLOOK_ORIGINAL'),
        (r'^_{5,}\s*From:', 'OUTLOOK_UNDERLINE'),
        (r'^From:\s+.+\nSent:\s+.+\nTo:\s+', 'OUTLOOK_HEADER'),
        
        # Gmail separators
        (r'^On\s+\w+,\s+\w+\s+\d{1,2},\s+\d{4}\s+at\s+\d{1,2}:\d{2}\s*(?:AM|PM|am|pm)?,\s*.*?wrote:', 'GMAIL_DATETIME'),
        (r'^On\s+.+?wrote:', 'GMAIL_GENERIC'),
        
        # Forwarded message markers
        (r'^-{5,}\s*Forwarded Message\s*-{5,}', 'FORWARDED'),
        (r'^-{5,}\s*End Forwarded Message\s*-{5,}', 'END_FORWARDED'),
        
        # Microsoft Teams style
        (r'<div.*?class.*?email-quote.*?>', 'TEAMS_QUOTE'),
        
        # Generic separators
        (r'^-{10,}', 'GENERIC_SEPARATOR'),
        (r'^_{10,}', 'GENERIC_UNDERLINE'),
        
        # Subject: RE:/FW: patterns (start of previous conversation)
        (r'^\s*Subject:\s*(RE:|FW:|Fwd:)', 'SUBJECT_MARKER'),
        
        # "Sent:" markers
        (r'^\s*Sent:\s+\d{1,2}/\d{1,2}/\d{4}', 'SENT_DATE'),
        (r'^\s*Date:\s+\w+,\s+\w+\s+\d{1,2},\s+\d{4}', 'DATE_MARKER'),
    ]
    
    @staticmethod
    def extract_current_message_only(body: str) -> Dict:
        """
        Extract ONLY the current message, removing ALL previous conversations
        
        Returns:
        {
            'current_message': str,      # ONLY current message (clean)
            'is_threaded': bool,         # Was it a threaded email?
            'thread_count': int,         # How many messages total
            'separator_type': str,       # Which separator was detected
            'raw_body': str              # Original for reference
        }
        """
        result = {
            'current_message': body if body else '',
            'is_threaded': False,
            'thread_count': 1,
            'separator_type': None,
            'raw_body': body
        }
        
        if not body or not body.strip():
            return result
        
        # Find the earliest/first thread separator
        earliest_pos = len(body)
        separator_type = None
        
        # Try each separator pattern
        for pattern, sep_type in AdvancedEmailThreadParser.THREAD_SEPARATORS:
            try:
                match = re.search(
                    pattern,
                    body,
                    re.MULTILINE | re.IGNORECASE | re.DOTALL
                )
                
                if match and match.start() < earliest_pos:
                    earliest_pos = match.start()
                    separator_type = sep_type
                    logger.debug(f"Found separator: {sep_type} at position {match.start()}")
            
            except re.error as e:
                logger.warning(f"Regex error for pattern {sep_type}: {e}")
        
        # Extract only text BEFORE the first separator
        if earliest_pos < len(body):
            result['is_threaded'] = True
            result['separator_type'] = separator_type
            result['current_message'] = body[:earliest_pos].strip()
            
            # Count total messages in thread
            thread_matches = 0
            for pattern, _ in AdvancedEmailThreadParser.THREAD_SEPARATORS:
                try:
                    thread_matches += len(re.findall(pattern, body, re.MULTILINE | re.IGNORECASE))
                except:
                    pass
            
            result['thread_count'] = max(thread_matches + 1, 2)
        else:
            result['current_message'] = body.strip()
        
        # Clean up common artifacts
        result['current_message'] = AdvancedEmailThreadParser._cleanup_message(
            result['current_message']
        )
        
        logger.info(
            f"Extracted message - "
            f"Threaded: {result['is_threaded']}, "
            f"Messages: {result['thread_count']}, "
            f"Size: {len(result['current_message'])} chars"
        )
        
        return result
    
    @staticmethod
    def _cleanup_message(text: str) -> str:
        """
        Remove common artifacts that might remain after thread separation
        """
        if not text:
            return text
        
        # Remove trailing "-----Original Message-----" and similar
        text = re.sub(r'\s*-{5,}\s*(?:Original Message|Forwarded Message|End.*?Message)\s*-{5,}\s*$', '', text, flags=re.IGNORECASE)
        text = re.sub(r'\s*_{5,}\s*From:.*$', '', text, flags=re.IGNORECASE | re.DOTALL)
        
        # Remove "Sent:" lines at the end
        text = re.sub(r'\s*(?:Sent|Date):\s+.*?\n.*?To:.*?$', '', text, flags=re.IGNORECASE | re.DOTALL)
        
        # Remove quoted text markers (starts with >)
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # Skip lines that are clearly part of previous message
            if line.strip().startswith('>'):
                continue  # Skip quoted lines
            if re.match(r'^\s*From:\s+', line, re.IGNORECASE):
                break  # Stop at "From:" line
            if re.match(r'^\s*Sent:\s+', line, re.IGNORECASE):
                break  # Stop at "Sent:" line
            if re.match(r'^\s*Date:\s+', line, re.IGNORECASE):
                break  # Stop at "Date:" line
            
            cleaned_lines.append(line)
        
        text = '\n'.join(cleaned_lines).strip()
        
        # Remove multiple consecutive blank lines
        text = re.sub(r'\n\n\n+', '\n\n', text)
        
        return text
    
    @staticmethod
    def extract_all_messages_in_thread(body: str) -> list:
        """
        Extract ALL messages in the thread (useful for debugging/analysis)
        """
        messages = []
        
        # Split by main separators
        parts = re.split(
            r'(?:^|\n)(?:' +
            '|'.join([p[0] for p in AdvancedEmailThreadParser.THREAD_SEPARATORS]) +
            r')',
            body,
            flags=re.MULTILINE | re.IGNORECASE | re.DOTALL
        )
        
        for idx, part in enumerate(parts):
            if part.strip():
                messages.append({
                    'message_num': idx,
                    'content': part.strip(),
                    'length': len(part.strip())
                })
        
        return messages


# ============================================================================
# UPDATED INTEGRATION WITH EXISTING CODE
# ============================================================================

# In your extract_email_chain_from_outlook method, update like this:

def extract_email_chain_from_outlook(self):
    """Modified with ADVANCED thread parsing"""
    
    # ... existing setup code ...
    
    def worker():
        error_msg = None
        pythoncom.CoInitialize()
        
        try:
            # ... existing code for folder, dates, etc ...
            
            for item in all_items:
                try:
                    if getattr(item, "Class", None) == 43:
                        subject = item.Subject or ""
                        body = item.Body or ""
                        html_body = ""
                        
                        try:
                            html_body = item.HTMLBody
                        except Exception:
                            pass
                        
                        search_zone = f"{subject}\n{body}\n{html_body}"
                        found_tids = set(m.lower() for m in tid_re.findall(search_zone))
                        
                        for orig_tid in trade_ids:
                            if orig_tid.lower() in found_tids:
                                # ===== UPDATED: Use advanced thread parser =====
                                thread_info = AdvancedEmailThreadParser.extract_current_message_only(body)
                                
                                email_obj = {
                                    'trade_id': orig_tid,
                                    'subject': subject,
                                    'sender': getattr(item, "SenderName", ""),
                                    'recipient': getattr(item, "To", ""),
                                    'date': item.ReceivedTime.strftime("%Y-%m-%d %H:%M:%S") if item.ReceivedTime else "",
                                    
                                    # ===== EXTRACT ONLY CURRENT MESSAGE =====
                                    'body': thread_info['current_message'],
                                    
                                    # Thread metadata
                                    'is_threaded': thread_info['is_threaded'],
                                    'thread_count': thread_info['thread_count'],
                                    'separator_type': thread_info['separator_type'],
                                    
                                    # Keep raw for debugging if needed
                                    'raw_body': body
                                }
                                
                                matches_by_tradeid[orig_tid].append(email_obj)
                                all_emails.append(email_obj)
                
                except Exception as item_error:
                    logger.warning(f"Error processing item: {str(item_error)}")
                    pass
            
            gc.collect()
            
            # ... rest of existing code ...
            
            self.root.after(0, lambda: self.finish_extraction(all_emails, None))
        
        except Exception as e:
            error_msg = str(e)
            logger.error(f"Error: {error_msg}")
            gc.collect()
            self.root.after(0, lambda msg=error_msg: self.finish_extraction([], msg))
    
    threading.Thread(target=worker, daemon=True).start()

