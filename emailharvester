"""
Enhanced Email Entity Extractor with Pattern ID Tracking and MI Metrics
Integrates with your existing Tkinter app
"""

import os
import re
import json
import logging
from datetime import datetime
from collections import defaultdict, Counter
from typing import Dict, List
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# 1. PATTERN MANAGER WITH IDs (Updated Pattern_Config.json structure)
# ============================================================================

class PatternManager:
    """Manages regex patterns with unique IDs for tracking"""
    
    def __init__(self, config_file: str = "Pattern_Config.json"):
        self.config_file = config_file
        self.patterns = {}
        self.pattern_id_map = {}
        self.load_patterns()
    
    def load_patterns(self):
        """Load patterns from existing Pattern_Config.json with IDs"""
        if not os.path.exists(self.config_file):
            logger.warning(f"Pattern config not found: {self.config_file}")
            return
        
        with open(self.config_file, 'r') as f:
            config_data = json.load(f)
        
        # Add pattern IDs if not present
        for field_name, field_config in config_data.items():
            if isinstance(field_config, dict) and 'patterns' in field_config:
                patterns_list = field_config['patterns']
                
                for idx, pattern_entry in enumerate(patterns_list):
                    # Generate pattern ID if not present
                    if 'pattern_id' not in pattern_entry:
                        pattern_entry['pattern_id'] = f"{field_name.upper()}_PTN{idx+1:03d}"
                    
                    pattern_id = pattern_entry['pattern_id']
                    self.pattern_id_map[pattern_id] = {
                        'field': field_name,
                        'pattern': pattern_entry.get('pattern', ''),
                        'description': pattern_entry.get('description', ''),
                        'priority': idx + 1
                    }
        
        self.patterns = config_data
        
        # Save updated config with IDs
        self.save_patterns()
        logger.info(f"Loaded {len(self.pattern_id_map)} patterns with IDs")
    
    def save_patterns(self):
        """Save patterns back to config file"""
        with open(self.config_file, 'w') as f:
            json.dump(self.patterns, f, indent=4)
    
    def get_patterns_for_field(self, field_name: str) -> List[Dict]:
        """Get all patterns for a specific field"""
        field_config = self.patterns.get(field_name, {})
        return field_config.get('patterns', [])


# ============================================================================
# 2. USAGE TRACKER FOR MI METRICS
# ============================================================================

class PatternUsageTracker:
    """Track pattern usage for MI reporting"""
    
    def __init__(self, metrics_file: str = "pattern_usage_metrics.json"):
        self.metrics_file = metrics_file
        self.current_run_stats = defaultdict(lambda: {
            'attempts': 0,
            'matches': 0,
            'extracted_values': []
        })
        self.historical_stats = {}
        self.load_historical_metrics()
    
    def load_historical_metrics(self):
        """Load historical usage data"""
        if os.path.exists(self.metrics_file):
            try:
                with open(self.metrics_file, 'r') as f:
                    self.historical_stats = json.load(f)
            except Exception as e:
                logger.warning(f"Could not load metrics: {e}")
                self.historical_stats = {}
    
    def record_attempt(self, pattern_id: str):
        """Record a pattern usage attempt"""
        self.current_run_stats[pattern_id]['attempts'] += 1
    
    def record_match(self, pattern_id: str, extracted_value: str):
        """Record a successful pattern match"""
        self.current_run_stats[pattern_id]['matches'] += 1
        self.current_run_stats[pattern_id]['extracted_values'].append(extracted_value)
    
    def finalize_run(self, run_date: str):
        """Finalize current run and update historical stats"""
        # Update historical stats
        if run_date not in self.historical_stats:
            self.historical_stats[run_date] = {}
        
        for pattern_id, stats in self.current_run_stats.items():
            if pattern_id not in self.historical_stats[run_date]:
                self.historical_stats[run_date][pattern_id] = {
                    'total_attempts': 0,
                    'total_matches': 0,
                    'unique_values_count': 0
                }
            
            self.historical_stats[run_date][pattern_id]['total_attempts'] += stats['attempts']
            self.historical_stats[run_date][pattern_id]['total_matches'] += stats['matches']
            self.historical_stats[run_date][pattern_id]['unique_values_count'] = len(
                set(stats['extracted_values'])
            )
        
        # Save to file
        self.save_metrics()
        
        # Reset current run stats
        self.current_run_stats.clear()
    
    def save_metrics(self):
        """Save metrics to JSON file"""
        with open(self.metrics_file, 'w') as f:
            json.dump(self.historical_stats, f, indent=2)
        logger.info(f"Metrics saved to {self.metrics_file}")
    
    def get_pattern_success_rate(self, pattern_id: str) -> float:
        """Calculate overall success rate for a pattern"""
        total_attempts = 0
        total_matches = 0
        
        for date_stats in self.historical_stats.values():
            if pattern_id in date_stats:
                total_attempts += date_stats[pattern_id]['total_attempts']
                total_matches += date_stats[pattern_id]['total_matches']
        
        if total_attempts == 0:
            return 0.0
        return (total_matches / total_attempts) * 100.0
    
    def generate_mi_report(self, output_path: str):
        """Generate comprehensive MI report"""
        report_data = []
        
        # Aggregate stats across all dates
        pattern_aggregates = defaultdict(lambda: {
            'total_attempts': 0,
            'total_matches': 0,
            'dates_used': 0
        })
        
        for run_date, date_stats in self.historical_stats.items():
            for pattern_id, stats in date_stats.items():
                pattern_aggregates[pattern_id]['total_attempts'] += stats['total_attempts']
                pattern_aggregates[pattern_id]['total_matches'] += stats['total_matches']
                pattern_aggregates[pattern_id]['dates_used'] += 1
        
        # Build report rows
        for pattern_id, agg_stats in pattern_aggregates.items():
            attempts = agg_stats['total_attempts']
            matches = agg_stats['total_matches']
            success_rate = (matches / attempts * 100) if attempts > 0 else 0.0
            
            report_data.append({
                'Pattern ID': pattern_id,
                'Total Attempts': attempts,
                'Total Matches': matches,
                'Success Rate (%)': round(success_rate, 2),
                'Days Used': agg_stats['dates_used']
            })
        
        # Create DataFrame and save
        df = pd.DataFrame(report_data)
        df = df.sort_values('Total Matches', ascending=False)
        
        # Multi-sheet Excel
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Pattern Summary', index=False)
            
            # Daily breakdown
            daily_data = []
            for run_date, date_stats in self.historical_stats.items():
                for pattern_id, stats in date_stats.items():
                    daily_data.append({
                        'Date': run_date,
                        'Pattern ID': pattern_id,
                        'Attempts': stats['total_attempts'],
                        'Matches': stats['total_matches'],
                        'Unique Values': stats['unique_values_count']
                    })
            
            daily_df = pd.DataFrame(daily_data)
            daily_df.to_excel(writer, sheet_name='Daily Breakdown', index=False)
        
        logger.info(f"MI Report saved to {output_path}")
        return df


# ============================================================================
# 3. ENHANCED ENTITY EXTRACTION WITH TRACKING
# ============================================================================

class TrackedEntityExtractor:
    """Entity extractor with pattern tracking"""
    
    def __init__(self, pattern_manager: PatternManager, tracker: PatternUsageTracker):
        self.pattern_manager = pattern_manager
        self.tracker = tracker
    
    def extract_field(self, text: str, field_name: str) -> Dict:
        """Extract a field with pattern tracking"""
        patterns = self.pattern_manager.get_patterns_for_field(field_name)
        
        result = {
            'value': None,
            'pattern_id': None,
            'confidence': 0.0
        }
        
        for pattern_entry in patterns:
            pattern_id = pattern_entry.get('pattern_id', 'UNKNOWN')
            pattern_regex = pattern_entry.get('pattern', '')
            
            if not pattern_regex:
                continue
            
            # Record attempt
            self.tracker.record_attempt(pattern_id)
            
            try:
                match = re.search(pattern_regex, text, re.IGNORECASE | re.MULTILINE)
                if match:
                    extracted_value = match.group(1) if match.lastindex else match.group(0)
                    extracted_value = extracted_value.strip()
                    
                    if extracted_value:
                        # Record success
                        self.tracker.record_match(pattern_id, extracted_value)
                        
                        # Return first match (highest priority)
                        result = {
                            'value': extracted_value,
                            'pattern_id': pattern_id,
                            'confidence': 1.0
                        }
                        break
            
            except re.error as e:
                logger.error(f"Regex error in pattern {pattern_id}: {e}")
        
        return result
    
    def extract_all_fields(self, text: str, field_names: List[str]) -> Dict:
        """Extract multiple fields from text"""
        results = {}
        for field_name in field_names:
            results[field_name] = self.extract_field(text, field_name)
        return results


# ============================================================================
# 4. INTEGRATION WITH YOUR EXISTING TKINTER APP
# ============================================================================

def integrate_with_existing_app(self):
    """
    Add this to your existing EmailEntityExtractor class
    
    In your __init__ method, add:
        self.pattern_manager = PatternManager("Pattern_Config.json")
        self.usage_tracker = PatternUsageTracker()
        self.tracked_extractor = TrackedEntityExtractor(self.pattern_manager, self.usage_tracker)
    """
    pass

def extract_entities_with_tracking(self, email_body: str, email_subject: str) -> Dict:
    """
    Replace your existing entity extraction method with this
    
    Usage in your existing code:
        extracted = self.extract_entities_with_tracking(email['body'], email['subject'])
        trade_id = extracted['Trade_ID']['value']
        pattern_used = extracted['Trade_ID']['pattern_id']
    """
    full_text = f"{email_subject}\n\n{email_body}"
    
    # Your existing field names from config
    field_names = list(self.pattern_manager.patterns.keys())
    
    # Extract with tracking
    results = self.tracked_extractor.extract_all_fields(full_text, field_names)
    
    return results

def finish_extraction_with_mi(self):
    """
    Updated finish_extraction method with MI generation
    Call this at the end of your extraction process
    """
    # Your existing extraction logic...
    # [All your current email processing code]
    
    # After processing all emails, finalize tracking
    run_date = datetime.now().strftime("%Y-%m-%d")
    self.usage_tracker.finalize_run(run_date)
    
    # Generate MI report
    mi_report_path = os.path.join(
        self.out_path, 
        f"Pattern_MI_Report_{run_date}.xlsx"
    )
    self.usage_tracker.generate_mi_report(mi_report_path)
    
    logger.info(f"MI Report generated: {mi_report_path}")
    
    # Display summary in your GUI (optional)
    self.show_mi_summary()

def show_mi_summary(self):
    """Display MI summary in your existing entity_result_text widget"""
    summary_lines = [
        "="*60,
        "PATTERN USAGE SUMMARY",
        "="*60
    ]
    
    # Top 5 patterns used
    top_patterns = Counter()
    for pattern_id, stats in self.usage_tracker.current_run_stats.items():
        top_patterns[pattern_id] = stats['matches']
    
    summary_lines.append("\nTop 5 Patterns Used:")
    for pattern_id, count in top_patterns.most_common(5):
        pattern_info = self.pattern_manager.pattern_id_map.get(pattern_id, {})
        summary_lines.append(f"  {pattern_id}: {count} matches ({pattern_info.get('field', 'N/A')})")
    
    summary_lines.append("\n" + "="*60)
    
    summary_text = "\n".join(summary_lines)
    
    # Display in your existing text widget
    self.entity_result_text.insert(tk.END, f"\n\n{summary_text}")


# ============================================================================
# 5. UPDATED OUTPUT CSV FORMAT
# ============================================================================

def save_results_with_pattern_ids(self, results: List[Dict], output_csv: str):
    """
    Save extraction results with pattern IDs
    Each row now includes which pattern was used
    """
    enhanced_results = []
    
    for result in results:
        row = {
            'Trade_ID': result.get('Trade_ID', {}).get('value', ''),
            'Trade_ID_Pattern': result.get('Trade_ID', {}).get('pattern_id', ''),
            'Counterparty': result.get('Counterparty', {}).get('value', ''),
            'Counterparty_Pattern': result.get('Counterparty', {}).get('pattern_id', ''),
            'Amount': result.get('Amount', {}).get('value', ''),
            'Amount_Pattern': result.get('Amount', {}).get('pattern_id', ''),
            # ... add all your fields with their pattern IDs
        }
        enhanced_results.append(row)
    
    df = pd.DataFrame(enhanced_results)
    df.to_csv(output_csv, index=False)
    logger.info(f"Results with pattern IDs saved to {output_csv}")


# ============================================================================
# 6. EXAMPLE: COMPLETE INTEGRATION IN YOUR EXISTING CLASS
# ============================================================================

class EmailEntityExtractor:
    """Your existing class with added pattern tracking"""
    
    def __init__(self, root, dir_path, temp_path):
        # Your existing init code...
        self.root = root
        self.dir_path = dir_path
        self.temp_path = temp_path
        
        # NEW: Add pattern management and tracking
        self.pattern_manager = PatternManager("Pattern_Config.json")
        self.usage_tracker = PatternUsageTracker()
        self.tracked_extractor = TrackedEntityExtractor(
            self.pattern_manager, 
            self.usage_tracker
        )
        
        # Rest of your existing init...
    
    def extract_entities(self, email_body: str, email_subject: str) -> Dict:
        """Your extraction method with tracking"""
        full_text = f"{email_subject}\n\n{email_body}"
        field_names = list(self.pattern_manager.patterns.keys())
        results = self.tracked_extractor.extract_all_fields(full_text, field_names)
        return results
    
    def finish_extraction(self):
        """Your existing method with MI generation added"""
        # ... your existing extraction logic ...
        
        # NEW: Finalize tracking and generate MI report
        run_date = datetime.now().strftime("%Y-%m-%d")
        self.usage_tracker.finalize_run(run_date)
        
        mi_report_path = os.path.join(
            self.out_path,
            f"Pattern_MI_Report_{run_date}.xlsx"
        )
        self.usage_tracker.generate_mi_report(mi_report_path)
        
        # Show summary in UI
        self.show_mi_summary()
        
        messagebox.showinfo("Success", 
            f"Extraction complete!\nMI Report: {mi_report_path}")
