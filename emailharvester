"""
Enhanced Regex Pattern System with Pattern IDs and Usage Analytics
Tracks which patterns are used, success rates, and generates MI reports
"""

import os
import re
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from collections import defaultdict, Counter
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# 1. ENHANCED PATTERN CONFIG WITH IDs
# ============================================================================

class PatternConfig:
    """
    Pattern configuration with unique IDs for tracking
    Example config JSON structure:
    {
        "patterns": [
            {
                "pattern_id": "PTN001",
                "pattern_name": "Trade ID Standard",
                "entity_type": "trade_id",
                "regex": "Trade ID:\\s*([A-Z0-9\\-]+)",
                "description": "Standard trade ID format",
                "priority": 1,
                "active": true
            },
            ...
        ]
    }
    """
    
    def __init__(self, config_path: str = "pattern_config.json"):
        self.config_path = config_path
        self.patterns = []
        self.patterns_by_id = {}
        self.patterns_by_entity = defaultdict(list)
        self.load_patterns()
    
    def load_patterns(self):
        """Load patterns from JSON config"""
        if os.path.exists(self.config_path):
            with open(self.config_path, 'r') as f:
                config_data = json.load(f)
                self.patterns = config_data.get('patterns', [])
        else:
            # Create default config
            self.patterns = self._create_default_patterns()
            self.save_patterns()
        
        # Build indexes
        for pattern in self.patterns:
            if pattern.get('active', True):
                pattern_id = pattern['pattern_id']
                entity_type = pattern['entity_type']
                
                self.patterns_by_id[pattern_id] = pattern
                self.patterns_by_entity[entity_type].append(pattern)
        
        # Sort by priority
        for entity_type in self.patterns_by_entity:
            self.patterns_by_entity[entity_type].sort(
                key=lambda p: p.get('priority', 999)
            )
        
        logger.info(f"Loaded {len(self.patterns)} patterns from {self.config_path}")
    
    def save_patterns(self):
        """Save patterns to JSON config"""
        with open(self.config_path, 'w') as f:
            json.dump({'patterns': self.patterns}, f, indent=2)
        logger.info(f"Saved patterns to {self.config_path}")
    
    def _create_default_patterns(self) -> List[Dict]:
        """Create default pattern set with IDs"""
        return [
            # Trade ID patterns
            {
                "pattern_id": "PTN001",
                "pattern_name": "Trade ID - Standard Format",
                "entity_type": "trade_id",
                "regex": r"(?:Trade\s*ID|Package|Deal)\s*[:=#]?\s*([A-Z0-9\-]+)",
                "description": "Standard trade ID with prefix",
                "priority": 1,
                "active": True
            },
            {
                "pattern_id": "PTN002",
                "pattern_name": "Trade ID - Numeric Only",
                "entity_type": "trade_id",
                "regex": r"\b(\d{6,10})\b",
                "description": "Numeric trade ID 6-10 digits",
                "priority": 2,
                "active": True
            },
            
            # Amount patterns
            {
                "pattern_id": "PTN101",
                "pattern_name": "Amount - USD Symbol",
                "entity_type": "amount",
                "regex": r"\$\s*([\d,]+(?:\.\d{2})?(?:\s*[MBK])?)",
                "description": "Dollar amounts with optional M/B/K suffix",
                "priority": 1,
                "active": True
            },
            {
                "pattern_id": "PTN102",
                "pattern_name": "Amount - Currency Suffix",
                "entity_type": "amount",
                "regex": r"([\d,]+(?:\.\d{2})?)\s*(USD|EUR|GBP)",
                "description": "Amount with currency code",
                "priority": 2,
                "active": True
            },
            {
                "pattern_id": "PTN103",
                "pattern_name": "Amount - Word Format",
                "entity_type": "amount",
                "regex": r"([\d,]+(?:\.\d{2})?)\s*(million|billion)",
                "description": "Amount with word suffix",
                "priority": 3,
                "active": True
            },
            
            # Rate patterns
            {
                "pattern_id": "PTN201",
                "pattern_name": "Rate - Percentage",
                "entity_type": "rate",
                "regex": r"(\d+\.?\d*)\s*%",
                "description": "Rate as percentage",
                "priority": 1,
                "active": True
            },
            {
                "pattern_id": "PTN202",
                "pattern_name": "Rate - Basis Points",
                "entity_type": "rate",
                "regex": r"(\d+\.?\d*)\s*(?:bps|basis\s*points)",
                "description": "Rate in basis points",
                "priority": 2,
                "active": True
            },
            {
                "pattern_id": "PTN203",
                "pattern_name": "Rate - LIBOR Based",
                "entity_type": "rate",
                "regex": r"(LIBOR\s*[+\-]\s*\d+\.?\d*(?:\s*bps)?)",
                "description": "LIBOR plus/minus spread",
                "priority": 1,
                "active": True
            },
            
            # Tenor patterns
            {
                "pattern_id": "PTN301",
                "pattern_name": "Tenor - Year Format",
                "entity_type": "tenor",
                "regex": r"(\d+)[\-\s]*(?:year|yr|Y)\b",
                "description": "Tenor in years",
                "priority": 1,
                "active": True
            },
            {
                "pattern_id": "PTN302",
                "pattern_name": "Tenor - Month Format",
                "entity_type": "tenor",
                "regex": r"(\d+)[\-\s]*(?:month|mo|M)\b",
                "description": "Tenor in months",
                "priority": 2,
                "active": True
            },
            
            # Date patterns
            {
                "pattern_id": "PTN401",
                "pattern_name": "Date - MM/DD/YYYY",
                "entity_type": "date",
                "regex": r"(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})",
                "description": "US date format",
                "priority": 1,
                "active": True
            },
            {
                "pattern_id": "PTN402",
                "pattern_name": "Date - ISO Format",
                "entity_type": "date",
                "regex": r"(\d{4}-\d{2}-\d{2})",
                "description": "ISO date format YYYY-MM-DD",
                "priority": 2,
                "active": True
            },
            
            # Counterparty patterns
            {
                "pattern_id": "PTN501",
                "pattern_name": "Counterparty - Client Name",
                "entity_type": "counterparty",
                "regex": r"(?:Client|Counterparty|Customer):\s*([A-Za-z0-9\s&,\.]+?)(?:\.|$|\n)",
                "description": "Counterparty with prefix",
                "priority": 1,
                "active": True
            }
        ]
    
    def get_patterns_for_entity(self, entity_type: str) -> List[Dict]:
        """Get all active patterns for a specific entity type"""
        return self.patterns_by_entity.get(entity_type, [])
    
    def get_pattern_by_id(self, pattern_id: str) -> Optional[Dict]:
        """Get pattern by ID"""
        return self.patterns_by_id.get(pattern_id)


# ============================================================================
# 2. PATTERN USAGE TRACKER
# ============================================================================

class PatternUsageTracker:
    """Track pattern usage statistics for MI reporting"""
    
    def __init__(self, metrics_path: str = "pattern_metrics.json"):
        self.metrics_path = metrics_path
        self.session_start = datetime.now()
        self.usage_stats = defaultdict(lambda: {
            'attempts': 0,
            'successes': 0,
            'extracted_values': [],
            'last_used': None
        })
        self.load_metrics()
    
    def load_metrics(self):
        """Load historical metrics"""
        if os.path.exists(self.metrics_path):
            try:
                with open(self.metrics_path, 'r') as f:
                    data = json.load(f)
                    self.usage_stats = defaultdict(
                        lambda: {'attempts': 0, 'successes': 0, 'extracted_values': [], 'last_used': None},
                        data.get('usage_stats', {})
                    )
            except Exception as e:
                logger.warning(f"Could not load metrics: {e}")
    
    def save_metrics(self):
        """Save metrics to JSON"""
        data = {
            'session_start': self.session_start.isoformat(),
            'session_end': datetime.now().isoformat(),
            'usage_stats': dict(self.usage_stats)
        }
        with open(self.metrics_path, 'w') as f:
            json.dump(data, f, indent=2)
    
    def record_attempt(self, pattern_id: str):
        """Record pattern usage attempt"""
        self.usage_stats[pattern_id]['attempts'] += 1
    
    def record_success(self, pattern_id: str, extracted_value: str):
        """Record successful extraction"""
        self.usage_stats[pattern_id]['successes'] += 1
        self.usage_stats[pattern_id]['extracted_values'].append(extracted_value)
        self.usage_stats[pattern_id]['last_used'] = datetime.now().isoformat()
    
    def get_success_rate(self, pattern_id: str) -> float:
        """Calculate success rate for a pattern"""
        stats = self.usage_stats[pattern_id]
        attempts = stats['attempts']
        if attempts == 0:
            return 0.0
        return (stats['successes'] / attempts) * 100.0
    
    def get_top_patterns(self, n: int = 10) -> List[Tuple[str, int]]:
        """Get top N most used patterns"""
        pattern_usage = [
            (pattern_id, stats['successes'])
            for pattern_id, stats in self.usage_stats.items()
        ]
        return sorted(pattern_usage, key=lambda x: x[1], reverse=True)[:n]
    
    def generate_mi_report(self) -> pd.DataFrame:
        """Generate MI report as DataFrame"""
        report_data = []
        for pattern_id, stats in self.usage_stats.items():
            report_data.append({
                'Pattern ID': pattern_id,
                'Attempts': stats['attempts'],
                'Successes': stats['successes'],
                'Success Rate (%)': self.get_success_rate(pattern_id),
                'Last Used': stats['last_used'] or 'Never',
                'Unique Values': len(set(stats['extracted_values']))
            })
        
        df = pd.DataFrame(report_data)
        df = df.sort_values('Successes', ascending=False)
        return df


# ============================================================================
# 3. ENHANCED ENTITY EXTRACTOR WITH TRACKING
# ============================================================================

class TrackedEntityExtractor:
    """Entity extractor with pattern tracking and MI"""
    
    def __init__(self, config_path: str = "pattern_config.json"):
        self.pattern_config = PatternConfig(config_path)
        self.tracker = PatternUsageTracker()
        self.extraction_log = []  # Per-run extraction details
    
    def extract_entities(self, text: str, entity_type: str) -> List[Dict]:
        """
        Extract entities with pattern tracking
        Returns: List of {value, pattern_id, pattern_name}
        """
        results = []
        patterns = self.pattern_config.get_patterns_for_entity(entity_type)
        
        for pattern in patterns:
            pattern_id = pattern['pattern_id']
            pattern_name = pattern['pattern_name']
            regex = pattern['regex']
            
            # Record attempt
            self.tracker.record_attempt(pattern_id)
            
            try:
                matches = re.findall(regex, text, re.IGNORECASE)
                for match in matches:
                    # Handle tuple matches (from groups)
                    value = match if isinstance(match, str) else ' '.join(match)
                    value = value.strip()
                    
                    if value:
                        # Record success
                        self.tracker.record_success(pattern_id, value)
                        
                        results.append({
                            'value': value,
                            'pattern_id': pattern_id,
                            'pattern_name': pattern_name,
                            'entity_type': entity_type
                        })
                        
                        # Log extraction
                        self.extraction_log.append({
                            'timestamp': datetime.now().isoformat(),
                            'pattern_id': pattern_id,
                            'entity_type': entity_type,
                            'value': value
                        })
            
            except re.error as e:
                logger.error(f"Regex error in pattern {pattern_id}: {e}")
        
        return results
    
    def extract_all_entities(self, text: str) -> Dict[str, List[Dict]]:
        """Extract all entity types from text"""
        entity_types = ['trade_id', 'amount', 'rate', 'tenor', 'date', 'counterparty']
        
        all_entities = {}
        for entity_type in entity_types:
            all_entities[entity_type] = self.extract_entities(text, entity_type)
        
        return all_entities
    
    def generate_run_summary(self) -> Dict:
        """Generate summary for current extraction run"""
        entity_counts = Counter([log['entity_type'] for log in self.extraction_log])
        pattern_counts = Counter([log['pattern_id'] for log in self.extraction_log])
        
        return {
            'run_timestamp': datetime.now().isoformat(),
            'total_extractions': len(self.extraction_log),
            'entities_by_type': dict(entity_counts),
            'patterns_used': dict(pattern_counts),
            'top_pattern': pattern_counts.most_common(1)[0] if pattern_counts else None
        }
    
    def save_mi_report(self, output_path: str):
        """Save MI report to Excel with multiple sheets"""
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # Sheet 1: Pattern usage metrics
            mi_df = self.tracker.generate_mi_report()
            mi_df.to_excel(writer, sheet_name='Pattern Metrics', index=False)
            
            # Sheet 2: Current run extraction log
            if self.extraction_log:
                log_df = pd.DataFrame(self.extraction_log)
                log_df.to_excel(writer, sheet_name='Extraction Log', index=False)
            
            # Sheet 3: Run summary
            summary = self.generate_run_summary()
            summary_df = pd.DataFrame([summary])
            summary_df.to_excel(writer, sheet_name='Run Summary', index=False)
            
            # Sheet 4: Top patterns
            top_patterns = self.tracker.get_top_patterns(20)
            top_df = pd.DataFrame(top_patterns, columns=['Pattern ID', 'Success Count'])
            top_df.to_excel(writer, sheet_name='Top Patterns', index=False)
        
        logger.info(f"MI report saved to {output_path}")


# ============================================================================
# 4. INTEGRATION WITH EMAIL EXTRACTION
# ============================================================================

def process_emails_with_tracking(emails: List[Dict], config_path: str = "pattern_config.json") -> pd.DataFrame:
    """Process emails with pattern tracking and MI"""
    
    extractor = TrackedEntityExtractor(config_path)
    results = []
    
    for email in emails:
        text = email.get('body', '') + '\n' + email.get('subject', '')
        
        # Extract all entities
        entities = extractor.extract_all_entities(text)
        
        # Flatten results
        row = {
            'email_date': email.get('date'),
            'email_subject': email.get('subject'),
            'trade_ids': ', '.join([e['value'] for e in entities.get('trade_id', [])]),
            'trade_id_patterns': ', '.join(set([e['pattern_id'] for e in entities.get('trade_id', [])])),
            'amounts': ', '.join([e['value'] for e in entities.get('amount', [])]),
            'amount_patterns': ', '.join(set([e['pattern_id'] for e in entities.get('amount', [])])),
            'rates': ', '.join([e['value'] for e in entities.get('rate', [])]),
            'rate_patterns': ', '.join(set([e['pattern_id'] for e in entities.get('rate', [])])),
            'counterparties': ', '.join([e['value'] for e in entities.get('counterparty', [])])
        }
        
        results.append(row)
    
    # Save metrics
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    mi_report_path = f"pattern_mi_report_{timestamp}.xlsx"
    extractor.save_mi_report(mi_report_path)
    
    # Save tracker metrics
    extractor.tracker.save_metrics()
    
    return pd.DataFrame(results)


# ============================================================================
# 5. EXAMPLE USAGE
# ============================================================================

def main():
    """Demo: Pattern tracking and MI generation"""
    
    # Sample email data
    sample_emails = [
        {
            'date': '2025-11-07',
            'subject': 'Trade Confirmation',
            'body': 'Trade ID: ABC12345. Amount: $100M USD. Rate: 3.75%. Tenor: 5-year. Client: XYZ Corp.'
        },
        {
            'date': '2025-11-07',
            'subject': 'Package Deal',
            'body': 'Deal: PKG9876. Notional $50 million. LIBOR + 50bps. 10-year swap.'
        }
    ]
    
    # Process with tracking
    results_df = process_emails_with_tracking(sample_emails)
    
    print("\n" + "="*80)
    print("EXTRACTION RESULTS")
    print("="*80)
    print(results_df.to_string(index=False))
    
    print("\n" + "="*80)
    print("MI REPORT GENERATED: pattern_mi_report_<timestamp>.xlsx")
    print("="*80)


if __name__ == "__main__":
    main()
