"""
Optimized RAG Pattern Detection with Email Thread Filtering
- Fast extraction (only processes email body, excludes threads)
- Smart pattern detection with label-aware RAG
- Suggests pattern combinations
"""

import os
import re
import json
import logging
from typing import Dict, List, Set
from collections import defaultdict
from datetime import datetime
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# EMAIL THREAD CLEANER - Remove Previous Email Threads
# ============================================================================

class EmailThreadCleaner:
    """Clean email body to remove previous threads/headers/footers"""
    
    # Common email thread separators
    THREAD_MARKERS = [
        r'From:.*?Sent:.*?To:',  # Outlook style
        r'On.*?wrote:',  # Gmail style
        r'_{5,}',  # Horizontal lines
        r'Original Message',
        r'Forwarded message',
        r'---------- Forwarded message',
    ]
    
    @staticmethod
    def clean_email_body(body: str) -> str:
        """
        Extract only the current email body, remove threads
        
        Returns the text BEFORE first email thread marker
        """
        if not body:
            return ""
        
        # Find earliest thread marker
        earliest_pos = len(body)
        
        for marker_pattern in EmailThreadCleaner.THREAD_MARKERS:
            match = re.search(marker_pattern, body, re.IGNORECASE | re.MULTILINE)
            if match and match.start() < earliest_pos:
                earliest_pos = match.start()
        
        # Return text before thread
        clean_body = body[:earliest_pos].strip()
        
        logger.info(f"Cleaned email: {len(body)} → {len(clean_body)} chars")
        return clean_body


# ============================================================================
# OPTIMIZED UNSEEN PATTERN DETECTOR
# ============================================================================

class OptimizedUnseenPatternDetector:
    """
    Fast pattern detector with:
    1. Only checks entity's own patterns (not all patterns)
    2. Extracts label-specific patterns for RAG
    3. Suggests pattern combinations
    """
    
    def __init__(self, pattern_manager, knowledge_base):
        self.pattern_manager = pattern_manager
        self.knowledge_base = knowledge_base
        self.unseen_texts = defaultdict(list)
        
        # Build label-to-pattern mapping
        self.label_to_patterns = self._build_label_pattern_map()
        
        # Store all config patterns for library
        self.all_config_patterns = self._load_all_patterns()
    
    def _load_all_patterns(self) -> List[Dict]:
        """Load all patterns for library"""
        all_patterns = []
        for entity_name in self.pattern_manager.get_all_entity_names():
            patterns = self.pattern_manager.get_patterns_for_entity(entity_name)
            all_patterns.extend(patterns)
        return all_patterns
    
    def _build_label_pattern_map(self) -> Dict[str, List[Dict]]:
        """
        Build map of label → patterns that extract it
        
        Example:
        {
            'TradeID': [
                {'pattern': '(?P<TradeID>\\d{7,8})', 'pattern_id': 'PKG_PTN001'},
                {'pattern': '(?P<TradeID>\\w{8})', 'pattern_id': 'PKG_PTN002'}
            ],
            'Currency_1': [...]
        }
        """
        label_map = defaultdict(list)
        
        for entity_name in self.pattern_manager.get_all_entity_names():
            patterns = self.pattern_manager.get_patterns_for_entity(entity_name)
            
            for pattern_info in patterns:
                pattern_str = pattern_info.get('pattern', '')
                pattern_id = pattern_info.get('pattern_id', 'UNKNOWN')
                
                # Extract named groups (labels) from pattern
                named_groups = re.findall(r'\(\?P<(\w+)>', pattern_str)
                
                for label in named_groups:
                    label_map[label].append({
                        'label': label,
                        'pattern': pattern_str,
                        'pattern_id': pattern_id,
                        'entity_name': entity_name
                    })
        
        logger.info(f"Built label map with {len(label_map)} labels")
        return label_map
    
    def detect_unseen(self, text: str, entity_name: str, extracted_result: Dict) -> bool:
        """Detect unseen patterns (FAST: only tries entity's patterns)"""
        if not extracted_result.get('value'):
            # Only try patterns for THIS entity (not all patterns)
            candidates = self._extract_candidates_fast(text, entity_name)
            
            if candidates:
                self.unseen_texts[entity_name].extend(candidates)
                return True
        
        return False
    
    def _extract_candidates_fast(self, text: str, entity_name: str) -> List[Dict]:
        """
        FAST candidate extraction:
        - Only tries patterns for the specific entity
        - Extracts by label for better RAG suggestions
        """
        candidates = []
        seen_values = set()
        
        # Only get patterns for THIS entity
        entity_patterns = self.pattern_manager.get_patterns_for_entity(entity_name)
        
        logger.info(f"Trying {len(entity_patterns)} patterns for {entity_name}...")
        
        for pattern_info in entity_patterns:
            pattern_id = pattern_info.get('pattern_id', 'UNKNOWN')
            pattern_str = pattern_info.get('pattern', '')
            
            if not pattern_str:
                continue
            
            try:
                # Try pattern
                matches = re.finditer(pattern_str, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)
                
                for match in matches:
                    # Extract named groups
                    group_dict = match.groupdict()
                    
                    if group_dict:
                        # Extract each named group
                        for label, value in group_dict.items():
                            if value and value.strip() and value not in seen_values:
                                candidates.append({
                                    'value': value.strip(),
                                    'label': label,
                                    'pattern_id': pattern_id,
                                    'pattern_used': pattern_str[:80],
                                    'entity_name': entity_name,
                                    'extraction_method': 'label_extraction'
                                })
                                seen_values.add(value)
                    else:
                        # No named groups - use group 1 or full match
                        value = None
                        if match.lastindex and match.lastindex >= 1:
                            value = match.group(1).strip()
                        else:
                            value = match.group(0).strip()
                        
                        if value and value not in seen_values:
                            candidates.append({
                                'value': value,
                                'label': 'FULL_MATCH',
                                'pattern_id': pattern_id,
                                'pattern_used': pattern_str[:80],
                                'entity_name': entity_name,
                                'extraction_method': 'full_match'
                            })
                            seen_values.add(value)
            
            except Exception as e:
                logger.debug(f"Pattern {pattern_id} error: {e}")
        
        logger.info(f"Found {len(candidates)} candidates for {entity_name}")
        return candidates
    
    def get_unseen_summary(self) -> Dict:
        """Get summary for report"""
        summary = {}
        
        for entity_name, candidate_list in self.unseen_texts.items():
            # Group by label
            by_label = defaultdict(lambda: {'values': [], 'patterns_used': set()})
            
            for candidate in candidate_list:
                if isinstance(candidate, dict):
                    label = candidate.get('label', 'UNKNOWN')
                    value = candidate.get('value', str(candidate))
                    pattern = candidate.get('pattern_used', 'N/A')
                    
                    by_label[label]['values'].append(value)
                    by_label[label]['patterns_used'].add(pattern)
            
            summary[entity_name] = {
                'total_count': len(candidate_list),
                'by_label': {
                    label: {
                        'count': len(data['values']),
                        'examples': list(set(data['values']))[:10],
                        'pattern_count': len(data['patterns_used']),
                        'patterns_used': list(data['patterns_used'])[:3]
                    }
                    for label, data in by_label.items()
                }
            }
        
        return summary
    
    # For report compatibility
    @property
    def label_pattern_library(self):
        """Convert label_to_patterns to library format for report"""
        library = {}
        for label, patterns in self.label_to_patterns.items():
            library[label] = patterns
        return library
    
    @property
    def all_config_patterns(self):
        """Return all patterns for report"""
        return self._all_config_patterns
    
    @all_config_patterns.setter
    def all_config_patterns(self, value):
        self._all_config_patterns = value


# ============================================================================
# ENHANCED PATTERN SUGGESTION ENGINE
# ============================================================================

class EnhancedPatternSuggestionEngine:
    """
    Enhanced engine that:
    1. Suggests existing patterns by label similarity
    2. Suggests new pattern combinations
    """
    
    def __init__(self, knowledge_base, label_to_patterns):
        self.knowledge_base = knowledge_base
        self.label_to_patterns = label_to_patterns
    
    def suggest_patterns(self, entity_name: str, unseen_examples: List[str]) -> List[Dict]:
        """Generate smart pattern suggestions"""
        suggestions = []
        
        # Strategy 1: Find similar patterns from RAG knowledge base
        query = f"Entity: {entity_name}, examples: {', '.join(unseen_examples[:3])}"
        similar_patterns = self.knowledge_base.search_similar_patterns(query, top_k=5)
        
        for similar in similar_patterns:
            suggestions.append({
                'suggested_pattern': similar['pattern'][:150],
                'pattern_id': similar['pattern_id'],
                'method': 'RAG_SIMILARITY',
                'similarity_score': similar['similarity_score'],
                'based_on_pattern_id': similar['pattern_id'],
                'reasoning': f"Similar to {similar['entity_name']} patterns",
                'test_examples': unseen_examples[:3]
            })
        
        # Strategy 2: Suggest pattern combinations
        # Analyze which labels might need to be combined
        combination_suggestions = self._suggest_pattern_combinations(entity_name, unseen_examples)
        suggestions.extend(combination_suggestions)
        
        return suggestions
    
    def _suggest_pattern_combinations(self, entity_name: str, examples: List[str]) -> List[Dict]:
        """
        Suggest new combinations of existing label patterns
        
        Example: If we have TradeID pattern and Currency pattern separately,
        suggest combining them into one composite pattern
        """
        suggestions = []
        
        # Detect which labels might be present in examples
        potential_labels = self._detect_potential_labels(examples)
        
        if len(potential_labels) >= 2:
            # Suggest combining patterns
            combined_pattern_parts = []
            used_pattern_ids = []
            
            for label in potential_labels[:3]:  # Combine up to 3 labels
                if label in self.label_to_patterns:
                    # Get one pattern for this label
                    pattern_info = self.label_to_patterns[label][0]
                    # Extract just the named group part
                    named_group_match = re.search(r'\(\?P<' + label + r'>([^)]+)\)', pattern_info['pattern'])
                    if named_group_match:
                        combined_pattern_parts.append(f"(?P<{label}>{named_group_match.group(1)})")
                        used_pattern_ids.append(pattern_info['pattern_id'])
            
            if len(combined_pattern_parts) >= 2:
                # Create combined pattern
                combined = r'.*?'.join(combined_pattern_parts)
                
                suggestions.append({
                    'suggested_pattern': combined[:150],
                    'pattern_id': 'COMBINATION_' + '_'.join(potential_labels[:2]),
                    'method': 'PATTERN_COMBINATION',
                    'similarity_score': 0.75,
                    'based_on_pattern_id': ', '.join(used_pattern_ids),
                    'reasoning': f"Combination of {', '.join(potential_labels)} patterns",
                    'test_examples': examples[:3]
                })
        
        return suggestions
    
    def _detect_potential_labels(self, examples: List[str]) -> List[str]:
        """Detect which labels might be present in unseen examples"""
        potential_labels = []
        
        # Try each label's patterns on examples
        for label, pattern_list in self.label_to_patterns.items():
            for pattern_info in pattern_list[:2]:  # Try first 2 patterns per label
                pattern_str = pattern_info['pattern']
                
                try:
                    for example in examples[:5]:
                        if re.search(pattern_str, example, re.IGNORECASE):
                            if label not in potential_labels:
                                potential_labels.append(label)
                            break
                except:
                    pass
        
        return potential_labels


# ============================================================================
# COMPLETE EXTRACTOR (UPDATED)
# ============================================================================

class CompleteOfflineRAGExtractor:
    """Complete RAG extractor with all optimizations"""
    
    def __init__(self, pattern_manager, tracker):
        self.pattern_manager = pattern_manager
        self.tracker = tracker
        self.email_cleaner = EmailThreadCleaner()
        
        # Initialize components
        from offline_rag import OfflinePatternKnowledgeBase
        
        self.knowledge_base = OfflinePatternKnowledgeBase(pattern_manager.config_file)
        self.unseen_detector = OptimizedUnseenPatternDetector(pattern_manager, self.knowledge_base)
        self.suggestion_engine = EnhancedPatternSuggestionEngine(
            self.knowledge_base,
            self.unseen_detector.label_to_patterns
        )
    
    def extract_entities(self, email_data: Dict) -> Dict:
        """
        Extract entities from email (matching your function signature)
        
        Args:
            email_data: Dict with 'body', 'subject', etc.
        
        Returns:
            Dict with extraction results
        """
        # Clean email body (remove threads)
        raw_body = email_data.get('body', '')
        clean_body = self.email_cleaner.clean_email_body(raw_body)
        
        # Get entity names
        entity_names = self.pattern_manager.get_all_entity_names()
        
        results = {}
        entities = {}
        
        # Track current activity (from your code)
        current_activity = None
        
        # Process line by line (matching your existing logic)
        lines = clean_body.splitlines()
        lines = list(filter(None, lines))  # Remove empty lines
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Check for activity keywords (from your code)
            line_upper = line.upper()
            for keyword in getattr(self, 'activity_keywords', []):
                if keyword in line_upper:
                    current_activity = line_upper
                    break
            
            # Extract entities from line
            for entity_name in entity_names:
                patterns = self.pattern_manager.get_patterns_for_entity(entity_name)
                
                result = {
                    'value': None,
                    'pattern_id': None,
                    'entity_name': entity_name
                }
                
                for pattern_entry in patterns:
                    pattern_id = pattern_entry['pattern_id']
                    pattern_regex = pattern_entry['pattern']
                    
                    self.tracker.record_attempt(pattern_id)
                    
                    try:
                        match = re.search(pattern_regex, line, re.IGNORECASE | re.MULTILINE | re.DOTALL)
                        if match:
                            groupdict = match.groupdict()
                            
                            # Add activity type to extracted data
                            if current_activity:
                                groupdict['ActivityType'] = current_activity
                            
                            # Extract values
                            for k, v in groupdict.items():
                                if v:
                                    entities.setdefault(k, []).append(f"{v} (Body)")
                            
                            self.tracker.record_match(pattern_id, line)
                            result['value'] = line
                            result['pattern_id'] = pattern_id
                            break
                    except Exception as e:
                        logger.debug(f"Pattern {pattern_id} error: {e}")
                
                # Detect unseen patterns
                if not result['value']:
                    result['is_unseen'] = self.unseen_detector.detect_unseen(line, entity_name, result)
                
                results[entity_name] = result
        
        return {'results': results, 'entities': entities}
    
    def save_comprehensive_rag_report(self, output_path: str):
        """Save comprehensive RAG report (unchanged)"""
        logger.info(f"Generating comprehensive RAG report: {output_path}")
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            self._save_label_library_sheet(writer)
            self._save_unseen_overview_sheet(writer)
            self._save_candidates_by_label_sheet(writer)
            self._save_pattern_suggestions_sheet(writer)
            self._save_extraction_summary_sheet(writer)
        
        logger.info(f"✓ RAG report saved: {output_path}")
    
    # [All _save_* methods remain the same as previous version]
    
    def _save_label_library_sheet(self, writer):
        """Sheet 1: Label-to-Pattern Library"""
        library_data = []
        
        for label, pattern_list in self.unseen_detector.label_to_patterns.items():
            for pattern_info in pattern_list:
                library_data.append({
                    'Label': label,
                    'Pattern ID': pattern_info['pattern_id'],
                    'Entity': pattern_info['entity_name'],
                    'Pattern': pattern_info['pattern'][:100]
                })
        
        if library_data:
            pd.DataFrame(library_data).to_excel(writer, sheet_name='Label Patterns', index=False)
    
    def _save_unseen_overview_sheet(self, writer):
        """Sheet 2: Unseen Overview"""
        unseen_summary = self.unseen_detector.get_unseen_summary()
        overview_data = []
        
        for entity_name, data in unseen_summary.items():
            labels = ', '.join(data.get('by_label', {}).keys())
            all_examples = []
            for label_data in data.get('by_label', {}).values():
                all_examples.extend(label_data['examples'][:3])
            
            overview_data.append({
                'Entity': entity_name,
                'Total Candidates': data['total_count'],
                'Labels Found': labels,
                'Sample Values': ', '.join(all_examples[:5])
            })
        
        if overview_data:
            pd.DataFrame(overview_data).to_excel(writer, sheet_name='Unseen Overview', index=False)
    
    def _save_candidates_by_label_sheet(self, writer):
        """Sheet 3: Candidates Detail"""
        unseen_summary = self.unseen_detector.get_unseen_summary()
        detailed_data = []
        
        for entity_name, data in unseen_summary.items():
            for label, label_data in data.get('by_label', {}).items():
                for example in label_data['examples']:
                    detailed_data.append({
                        'Entity': entity_name,
                        'Label': label,
                        'Candidate Value': example,
                        'Count': label_data['count'],
                        'Patterns Used': label_data['pattern_count']
                    })
        
        if detailed_data:
            pd.DataFrame(detailed_data).to_excel(writer, sheet_name='Candidates Detail', index=False)
    
    def _save_pattern_suggestions_sheet(self, writer):
        """Sheet 4: RAG Suggestions"""
        unseen_summary = self.unseen_detector.get_unseen_summary()
        suggestions_data = []
        
        for entity_name, data in unseen_summary.items():
            all_examples = []
            for label_data in data.get('by_label', {}).values():
                all_examples.extend(label_data['examples'][:5])
            
            if all_examples:
                suggestions = self.suggestion_engine.suggest_patterns(entity_name, all_examples)
                
                for sug in suggestions:
                    suggestions_data.append({
                        'Entity': entity_name,
                        'Suggested Pattern': sug['suggested_pattern'],
                        'Method': sug['method'],
                        'Similarity': sug['similarity_score'],
                        'Based On': sug['based_on_pattern_id'],
                        'Reasoning': sug['reasoning']
                    })
        
        if suggestions_data:
            pd.DataFrame(suggestions_data).to_excel(writer, sheet_name='RAG Suggestions', index=False)
    
    def _save_extraction_summary_sheet(self, writer):
        """Sheet 5: Summary"""
        unseen_summary = self.unseen_detector.get_unseen_summary()
        
        total_entities = len(unseen_summary)
        total_candidates = sum(d['total_count'] for d in unseen_summary.values())
        
        summary_data = [
            {'Metric': 'Entities with Unseen Patterns', 'Value': total_entities},
            {'Metric': 'Total Candidates', 'Value': total_candidates},
            {'Metric': 'Config Patterns', 'Value': len(self.unseen_detector.all_config_patterns)}
        ]
        
        pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)


# Usage in your existing code:
# extractor = CompleteOfflineRAGExtractor(pattern_manager, tracker)
# result = extractor.extract_entities(email_data)
# extractor.save_comprehensive_rag_report("report.xlsx")
