"""
DEADLOCK-FREE RAG Processor
- Uses non-blocking queue handling
- Proper thread lifecycle management
- No queue.join() waiting on busy threads
"""

import re
import logging
import threading
import queue
from typing import Dict, List
from collections import defaultdict
from datetime import datetime
import pandas as pd

logger = logging.getLogger(__name__)


# ============================================================================
# DEADLOCK-FREE RAG PROCESSOR
# ============================================================================

class SimpleRAGProcessor:
    """Lightweight RAG - NO DEADLOCK"""
    
    def __init__(self, pattern_manager, knowledge_base):
        self.pattern_manager = pattern_manager
        self.knowledge_base = knowledge_base
        
        # Extract config patterns once
        self.config_patterns = self._extract_config_patterns()
        logger.info(f"Loaded {len(self.config_patterns)} patterns")
        
        # Queue and storage with maxsize to prevent blocking
        self.unseen_queue = queue.Queue(maxsize=500)
        self.unseen_data = defaultdict(list)
        
        # Thread control
        self.is_running = False
        self.processor_thread = None
        
        # Stop event
        self.stop_event = threading.Event()
    
    def _extract_config_patterns(self) -> Dict:
        """Extract all patterns from config"""
        patterns = {}
        
        for entity_name in self.pattern_manager.get_all_entity_names():
            entity_patterns = self.pattern_manager.get_patterns_for_entity(entity_name)
            
            for pattern_info in entity_patterns:
                pattern_id = pattern_info.get('pattern_id')
                pattern_str = pattern_info.get('pattern', '')
                
                if pattern_id and pattern_str:
                    try:
                        patterns[pattern_id] = {
                            'pattern': pattern_str,
                            'entity': entity_name,
                            'compiled': re.compile(pattern_str, re.IGNORECASE | re.MULTILINE | re.DOTALL)
                        }
                    except Exception as e:
                        logger.debug(f"Pattern {pattern_id} error: {e}")
        
        return patterns
    
    def start(self):
        """Start background thread"""
        if self.is_running:
            logger.info("RAG processor already running")
            return
        
        self.is_running = True
        self.stop_event.clear()
        
        self.processor_thread = threading.Thread(
            target=self._process_queue,
            daemon=True,
            name="RAG-Processor"
        )
        self.processor_thread.start()
        logger.info("RAG processor started")
    
    def add_unseen_pattern(self, line: str, entity_name: str):
        """Queue unseen line - NON-BLOCKING"""
        if not line or not line.strip():
            return
        
        # Don't block if queue is full
        try:
            self.unseen_queue.put_nowait({
                'line': line.strip(),
                'entity_name': entity_name,
                'timestamp': datetime.now()
            })
        except queue.Full:
            logger.warning("RAG queue full - dropping item")
    
    def _process_queue(self):
        """Background thread: process unseen patterns - NON-BLOCKING"""
        logger.info("RAG processor thread running...")
        processed = 0
        
        while self.is_running:
            try:
                # Non-blocking get with timeout
                item = self.unseen_queue.get(timeout=0.2)
                
                line = item['line']
                entity_name = item['entity_name']
                
                # Find closest matching patterns
                closest = self._find_closest_patterns(line)
                
                # Store analysis
                if closest:
                    self.unseen_data[entity_name].append({
                        'line': line,
                        'closest_patterns': closest,
                        'timestamp': item['timestamp']
                    })
                
                processed += 1
                
                # Mark task as done (but don't wait for join)
                self.unseen_queue.task_done()
                
            except queue.Empty:
                # No items in queue - that's OK
                continue
            except Exception as e:
                logger.debug(f"RAG error: {e}")
        
        logger.info(f"RAG processor stopped (processed {processed} items)")
    
    def _find_closest_patterns(self, line: str, top_k: int = 3) -> List[Dict]:
        """Find closest matching patterns"""
        matches = []
        
        for pattern_id, pattern_info in self.config_patterns.items():
            try:
                match = pattern_info['compiled'].search(line)
                
                if match:
                    # Extract data
                    extracted = {k: v for k, v in match.groupdict().items() if v}
                    
                    matches.append({
                        'pattern_id': pattern_id,
                        'entity_name': pattern_info['entity'],
                        'pattern': pattern_info['pattern'][:100],
                        'extracted': extracted,
                        'confidence': len(extracted) / max(len(match.groupdict()), 1)
                    })
            
            except Exception as e:
                logger.debug(f"Match error: {e}")
        
        matches.sort(key=lambda x: x['confidence'], reverse=True)
        return matches[:top_k]
    
    def stop_and_wait(self, timeout: float = 2.0):
        """Stop processor - NO DEADLOCK"""
        logger.info("Stopping RAG processor...")
        
        # Signal stop
        self.is_running = False
        self.stop_event.set()
        
        # Drain remaining items quickly (non-blocking)
        drained = 0
        while True:
            try:
                item = self.unseen_queue.get_nowait()
                line = item['line']
                entity_name = item['entity_name']
                closest = self._find_closest_patterns(line)
                
                if closest:
                    self.unseen_data[entity_name].append({
                        'line': line,
                        'closest_patterns': closest,
                        'timestamp': item['timestamp']
                    })
                
                drained += 1
                self.unseen_queue.task_done()
            
            except queue.Empty:
                break
            except Exception as e:
                logger.debug(f"Drain error: {e}")
                break
        
        logger.info(f"Drained {drained} remaining items")
        
        # Wait for thread with timeout (not on queue.join)
        if self.processor_thread and self.processor_thread.is_alive():
            self.processor_thread.join(timeout=timeout)
            
            if self.processor_thread.is_alive():
                logger.warning("RAG processor thread still alive (will exit as daemon)")
        
        logger.info(f"RAG stopped. Total unseen: {sum(len(v) for v in self.unseen_data.values())}")
    
    def get_results(self) -> Dict:
        """Get unseen data"""
        return dict(self.unseen_data)
    
    def save_rag_report(self, output_path: str):
        """Save RAG report"""
        logger.info(f"Saving: {output_path}")
        
        results = self.get_results()
        
        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                
                # Sheet 1: Config Patterns
                patterns_data = [
                    {
                        'Pattern ID': pattern_id,
                        'Entity': pattern_info['entity'],
                        'Pattern': pattern_info['pattern'][:150]
                    }
                    for pattern_id, pattern_info in self.config_patterns.items()
                ]
                
                if patterns_data:
                    pd.DataFrame(patterns_data).to_excel(writer, sheet_name='Config Patterns', index=False)
                
                # Sheet 2: Unseen Patterns Detected
                unseen_data = []
                for entity, analyses in results.items():
                    for analysis in analyses:
                        unseen_data.append({
                            'Entity': entity,
                            'Unseen Line': analysis['line'][:80],
                            'Full Line': analysis['line'],
                        })
                
                if unseen_data:
                    pd.DataFrame(unseen_data).to_excel(writer, sheet_name='Unseen Patterns', index=False)
                
                # Sheet 3: Suggestions
                suggestions_data = []
                for entity, analyses in results.items():
                    for analysis in analyses:
                        for closest in analysis['closest_patterns']:
                            suggestions_data.append({
                                'Unseen Line': analysis['line'][:60],
                                'Suggested Pattern': closest['pattern_id'],
                                'Confidence': f"{closest['confidence']:.1%}",
                                'Extracted': str(closest['extracted'])[:100]
                            })
                
                if suggestions_data:
                    pd.DataFrame(suggestions_data).to_excel(writer, sheet_name='Suggestions', index=False)
                
                # Sheet 4: Summary
                summary_data = [
                    {'Metric': 'Total Config Patterns', 'Value': len(self.config_patterns)},
                    {'Metric': 'Unseen Patterns Found', 'Value': sum(len(v) for v in results.values())},
                ]
                
                pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)
            
            logger.info(f"✓ Report saved: {output_path}")
        
        except Exception as e:
            logger.error(f"Report save error: {e}")


# ============================================================================
# RAG WRAPPER - NO DEADLOCK
# ============================================================================

class RAGEnabledExtractor:
    """RAG wrapper - deadlock-free"""
    
    def __init__(self, pattern_manager, tracker):
        self.pattern_manager = pattern_manager
        self.tracker = tracker
        
        try:
            from offline_rag import OfflinePatternKnowledgeBase
            knowledge_base = OfflinePatternKnowledgeBase(pattern_manager.config_file)
        except:
            knowledge_base = None
        
        self.rag_processor = SimpleRAGProcessor(pattern_manager, knowledge_base)
        self.rag_processor.start()
        logger.info("RAGEnabledExtractor initialized")
    
    def queue_unseen(self, line: str, entity_name: str):
        """Queue unseen line - non-blocking"""
        self.rag_processor.add_unseen_pattern(line, entity_name)
    
    def finish_and_generate_report(self, report_path: str = None):
        """Finish and generate report - no deadlock"""
        logger.info("Finalizing RAG...")
        
        # Stop processor (with short timeout)
        self.rag_processor.stop_and_wait(timeout=1.5)
        
        # Generate report
        if report_path:
            self.rag_processor.save_rag_report(report_path)
        
        return self.rag_processor.get_results()


# ============================================================================
# EXTRACTION - DEADLOCK-FREE
# ============================================================================

def extract_entities(self):
    """Extract entities - DEADLOCK-FREE"""
    
    if self.selected_email is None:
        messagebox.showwarning("No Selection", "Please select an email")
        return
    
    try:
        entity_json = self.entity_text.get(1.0, tk.END).strip()
        self.entity_definitions = json.loads(entity_json)
    except json.JSONDecodeError as e:
        messagebox.showerror("JSON Error", f"Invalid JSON: {str(e)}")
        return
    
    try:
        self.clear_results()
        
        # IMPORTANT: Stop previous RAG and create new one
        if hasattr(self, 'rag_extractor') and self.rag_extractor:
            logger.info("Stopping previous RAG processor...")
            self.rag_extractor.rag_processor.stop_and_wait(timeout=1.0)
            self.rag_extractor = None
        
        # Create fresh RAG processor for this extraction
        logger.info("Creating new RAG processor...")
        self.rag_extractor = RAGEnabledExtractor(self.pattern_manager, self.usage_tracker)
        
        # Get email data
        email_data = self.selected_email
        entity_names = self.pattern_manager.get_all_entity_names()
        results = {}
        entities = {}
        
        logger.info(f"Processing: {email_data['subject']}")
        print(f"\n[1/2] Extracting entities...")
        
        # Process email body
        email_lines = email_data['body'].splitlines()
        email_lines = list(filter(None, email_lines))
        
        current_activity = None
        matched_count = 0
        unseen_count = 0
        
        for line in email_lines:
            line = line.strip()
            if not line:
                continue
            
            # Check for activity keywords
            line_upper = line.upper()
            for keyword in self.activity_keywords:
                if keyword in line_upper:
                    current_activity = line_upper
                    break
            
            # YOUR EXISTING EXTRACTION LOGIC
            extracted_from_line = False
            
            for entity_name in entity_names:
                patterns = self.pattern_manager.get_patterns_for_entity(entity_name)
                
                result = {
                    'value': None,
                    'pattern_id': None,
                    'entity_name': entity_name
                }
                
                for pattern_entry in patterns:
                    entity_type = pattern_entry.get('entity_type', 'pattern')
                    
                    if entity_type == "pattern":
                        pattern_id = pattern_entry['pattern_id']
                        pattern_regex = pattern_entry['pattern']
                        
                        self.usage_tracker.record_attempt(pattern_id)
                        
                        try:
                            if self.attribute_count_check(pattern_regex, line):
                                regex = re.compile(pattern_regex, re.IGNORECASE)
                                matches = regex.finditer(line)
                                
                                for match in matches:
                                    groupdict = match.groupdict()
                                    
                                    if current_activity:
                                        groupdict['ActivityType'] = current_activity
                                    
                                    for k, v in groupdict.items():
                                        if v:
                                            entities.setdefault(k, []).append(f"{v}")
                                    
                                    self.usage_tracker.record_match(pattern_id, line)
                                    result['value'] = line
                                    result['pattern_id'] = pattern_id
                                    extracted_from_line = True
                                    matched_count += 1
                                    break
                        
                        except re.error as regex_error:
                            logger.error(f"Regex error {pattern_id}: {regex_error}")
                    
                    elif entity_type == "gazetteer":
                        entity_def = self.entity_definitions.get(entity_name, {})
                        gazetteer_vals = entity_def.get("values", [])
                        subject_vals = self.extract_with_gazetteer(email_data['subject'], gazetteer_vals)
                        body_vals = self.extract_with_gazetteer(line, gazetteer_vals)
                        
                        all_vals = subject_vals + body_vals
                        
                        if all_vals:
                            entities[entity_name] = all_vals
                            extracted_from_line = True
                
                results[entity_name] = result
            
            # If no pattern matched, queue for RAG (non-blocking)
            if not extracted_from_line:
                unseen_count += 1
                self.rag_extractor.queue_unseen(line, "Trade")
        
        logger.info(f"Extraction: {matched_count} matched, {unseen_count} unseen")
        
        # Display results
        self.entity_result_text.delete(1.0, tk.END)
        
        if entities:
            for entity_name, vals in entities.items():
                self.entity_result_text.insert(tk.END, f"{entity_name}:\n")
                for v in vals:
                    self.entity_result_text.insert(tk.END, f"  - {v}\n")
        else:
            self.entity_result_text.insert(tk.END, "No entities found")
        
        self.finish_extraction_with_mi()
        
        # Generate RAG report
        print(f"\n[2/2] Generating RAG report...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        rag_report_path = f"RAG_Pattern_Analysis_{timestamp}.xlsx"
        
        try:
            rag_results = self.rag_extractor.finish_and_generate_report(rag_report_path)
            
            print(f"✓ Complete!")
            print(f"  Matched: {matched_count}")
            print(f"  Unseen: {unseen_count}")
            print(f"  Report: {rag_report_path}")
            
            messagebox.showinfo("Success", 
                f"Extraction complete!\n\n"
                f"Matched: {matched_count}\n"
                f"Unseen: {unseen_count}\n\n"
                f"Report: {rag_report_path}")
        
        except Exception as rag_error:
            logger.error(f"RAG error: {rag_error}")
            messagebox.showwarning("Warning",
                f"Extraction complete!\n\n"
                f"Matched: {matched_count}\n"
                f"Unseen: {unseen_count}\n\n"
                f"RAG report error: {str(rag_error)}")
    
    except Exception as e:
        logger.error(f"Error: {str(e)}", exc_info=True)
        messagebox.showerror("Error", f"Failed: {str(e)}")
