"""
Email Harvester - Streamlit Version with MAPI Support
Complete migration from Tkinter with enhanced visualizations and multi-email selection
Uses MAPI instead of Exchange, with mailbox list, folder list, and threading support
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
import json
import re
import logging
import time
from collections import defaultdict
import glob
import shutil
from pathlib import Path
import threading
from queue import Queue

# MAPI/Outlook imports
try:
    import win32com.client
    from win32com.client import Dispatch
    import pythoncom
    MAPI_AVAILABLE = True
except ImportError:
    MAPI_AVAILABLE = False
    st.warning("‚ö†Ô∏è win32com not installed. MAPI connectivity disabled. Install: pip install pywin32")

# Set page config
st.set_page_config(
    page_title="Email Harvester Pro",
    page_icon="üìß",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .stButton>button {
        width: 100%;
    }
    .success-box {
        padding: 1rem;
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        border-radius: 0.25rem;
        margin: 1rem 0;
    }
    .warning-box {
        padding: 1rem;
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        border-radius: 0.25rem;
        margin: 1rem 0;
    }
    .error-box {
        padding: 1rem;
        background-color: #f8d7da;
        border-left: 4px solid #dc3545;
        border-radius: 0.25rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# SESSION STATE INITIALIZATION
# ============================================================================

def init_session_state():
    """Initialize all session state variables"""
    
    # Outlook/MAPI connection
    if 'outlook' not in st.session_state:
        st.session_state.outlook = None
    if 'mapi' not in st.session_state:
        st.session_state.mapi = None
    if 'connected' not in st.session_state:
        st.session_state.connected = False
    
    # Mailbox and folder lists
    if 'mailboxes' not in st.session_state:
        st.session_state.mailboxes = []
    if 'selected_mailbox' not in st.session_state:
        st.session_state.selected_mailbox = None
    if 'folders' not in st.session_state:
        st.session_state.folders = []
    if 'selected_folder' not in st.session_state:
        st.session_state.selected_folder = None
    
    # Email data
    if 'emails' not in st.session_state:
        st.session_state.emails = []
    if 'selected_emails' not in st.session_state:
        st.session_state.selected_emails = []
    if 'email_df' not in st.session_state:
        st.session_state.email_df = pd.DataFrame()
    
    # Extraction results
    if 'extraction_results' not in st.session_state:
        st.session_state.extraction_results = []
    if 'extraction_df' not in st.session_state:
        st.session_state.extraction_df = pd.DataFrame()
    if 'matched_count' not in st.session_state:
        st.session_state.matched_count = 0
    if 'unseen_count' not in st.session_state:
        st.session_state.unseen_count = 0
    if 'conversation_count' not in st.session_state:
        st.session_state.conversation_count = 0
    if 'table_count' not in st.session_state:
        st.session_state.table_count = 0
    
    # Configuration
    if 'config' not in st.session_state:
        st.session_state.config = {
            'entity_definitions': {},
            'selected_columns': [],
            'gazetteer_data': {},
            'static_headers': []
        }
    
    # Pattern cache
    if 'compiled_patterns' not in st.session_state:
        st.session_state.compiled_patterns = {}
    
    # RAG processor
    if 'rag_extractor' not in st.session_state:
        st.session_state.rag_extractor = None
    
    # Paths
    if 'temp_path' not in st.session_state:
        st.session_state.temp_path = "./temp_extraction"
    if 'out_path' not in st.session_state:
        st.session_state.out_path = "./output"
    
    # Threading
    if 'fetch_thread' not in st.session_state:
        st.session_state.fetch_thread = None
    if 'extract_thread' not in st.session_state:
        st.session_state.extract_thread = None
    if 'fetch_queue' not in st.session_state:
        st.session_state.fetch_queue = Queue()
    if 'extract_queue' not in st.session_state:
        st.session_state.extract_queue = Queue()
    
    # Create directories
    os.makedirs(st.session_state.temp_path, exist_ok=True)
    os.makedirs(st.session_state.out_path, exist_ok=True)


# ============================================================================
# MAPI/OUTLOOK CONNECTION
# ============================================================================

def connect_to_outlook():
    """Connect to Outlook via MAPI"""
    try:
        # Initialize COM for threading
        pythoncom.CoInitialize()
        
        outlook = Dispatch("Outlook.Application")
        mapi = outlook.GetNamespace("MAPI")
        
        # Get list of mailboxes (accounts)
        mailboxes = []
        for i in range(1, mapi.Folders.Count + 1):
            folder = mapi.Folders.Item(i)
            mailboxes.append({
                'name': folder.Name,
                'index': i,
                'folder_obj': folder
            })
        
        return outlook, mapi, mailboxes, True
    
    except Exception as e:
        logger.error(f"Outlook connection error: {str(e)}")
        return None, None, [], False


def get_folder_list(mailbox_folder):
    """Get list of folders from selected mailbox"""
    folders = []
    
    def traverse_folders(folder, parent_path=""):
        """Recursively traverse folders"""
        try:
            folder_path = f"{parent_path}/{folder.Name}" if parent_path else folder.Name
            folders.append({
                'name': folder.Name,
                'path': folder_path,
                'folder_obj': folder
            })
            
            # Traverse subfolders
            if folder.Folders.Count > 0:
                for i in range(1, folder.Folders.Count + 1):
                    try:
                        subfolder = folder.Folders.Item(i)
                        traverse_folders(subfolder, folder_path)
                    except:
                        continue
        except Exception as e:
            logger.warning(f"Error traversing folder: {str(e)}")
    
    try:
        traverse_folders(mailbox_folder)
    except Exception as e:
        logger.error(f"Error getting folder list: {str(e)}")
    
    return folders


def fetch_emails_mapi(folder_obj, start_date, end_date, max_emails=1000, progress_queue=None):
    """Fetch emails from MAPI folder using threading"""
    try:
        # Initialize COM in thread
        pythoncom.CoInitialize()
        
        emails = []
        items = folder_obj.Items
        items.Sort("[ReceivedTime]", True)  # Sort by received time, descending
        
        # Filter by date
        start_str = start_date.strftime("%m/%d/%Y")
        end_str = end_date.strftime("%m/%d/%Y")
        filter_str = f"[ReceivedTime] >= '{start_str}' AND [ReceivedTime] <= '{end_str}'"
        
        try:
            items = items.Restrict(filter_str)
        except:
            logger.warning("Date filtering failed, fetching all items")
        
        total = min(items.Count, max_emails)
        logger.info(f"Found {items.Count} items, fetching {total}")
        
        for i in range(1, total + 1):
            try:
                item = items.Item(i)
                
                # Extract email data
                email_data = {
                    'subject': getattr(item, 'Subject', ''),
                    'sender': getattr(item, 'SenderEmailAddress', ''),
                    'sender_name': getattr(item, 'SenderName', ''),
                    'date': getattr(item, 'ReceivedTime', datetime.now()),
                    'body': getattr(item, 'Body', ''),
                    'conversation_id': getattr(item, 'ConversationID', ''),
                    'item_id': getattr(item, 'EntryID', ''),
                    'has_attachments': getattr(item, 'Attachments', []) and getattr(item, 'Attachments').Count > 0,
                    'importance': getattr(item, 'Importance', 1),  # 0=Low, 1=Normal, 2=High
                    'size': getattr(item, 'Size', 0)
                }
                
                emails.append(email_data)
                
                # Send progress update
                if progress_queue and i % 10 == 0:
                    progress_queue.put({
                        'type': 'progress',
                        'current': i,
                        'total': total,
                        'message': f"Fetching email {i}/{total}"
                    })
                
            except Exception as e:
                logger.warning(f"Error processing email {i}: {str(e)}")
                continue
        
        # Send completion message
        if progress_queue:
            progress_queue.put({
                'type': 'complete',
                'emails': emails,
                'message': f"Fetched {len(emails)} emails successfully"
            })
        
        pythoncom.CoUninitialize()
        return emails
    
    except Exception as e:
        logger.error(f"Error fetching emails: {str(e)}")
        if progress_queue:
            progress_queue.put({
                'type': 'error',
                'message': str(e)
            })
        pythoncom.CoUninitialize()
        return []


# ============================================================================
# PATTERN MATCHING & EXTRACTION (Same as before)
# ============================================================================

def compile_patterns(entity_definitions):
    """Compile regex patterns for faster matching"""
    compiled = {}
    
    for entity_name, entity_config in entity_definitions.items():
        if 'patterns' in entity_config:
            patterns = entity_config['patterns']
            compiled[entity_name] = []
            
            for pattern_config in patterns:
                try:
                    pattern = pattern_config.get('pattern', '')
                    regex = re.compile(pattern, re.IGNORECASE | re.MULTILINE)
                    compiled[entity_name].append({
                        'regex': regex,
                        'config': pattern_config
                    })
                except Exception as e:
                    logger.error(f"Error compiling pattern for {entity_name}: {str(e)}")
    
    return compiled


def extract_with_patterns(text, compiled_patterns, entity_names):
    """Extract entities using compiled regex patterns"""
    results = {}
    
    for entity_name in entity_names:
        if entity_name not in compiled_patterns:
            continue
        
        matches = []
        for pattern_obj in compiled_patterns[entity_name]:
            regex = pattern_obj['regex']
            config = pattern_obj['config']
            
            for match in regex.finditer(text):
                match_text = match.group(0)
                matches.append({
                    'text': match_text,
                    'start': match.start(),
                    'end': match.end(),
                    'pattern_id': config.get('id', 'unknown')
                })
        
        results[entity_name] = matches
    
    return results


def extract_with_gazetteer(text, gazetteer_data, entity_names):
    """Extract entities using gazetteer (dictionary lookup)"""
    results = {}
    
    for entity_name in entity_names:
        if entity_name not in gazetteer_data:
            continue
        
        matches = []
        terms = gazetteer_data[entity_name]
        
        for term in terms:
            pattern = re.compile(re.escape(term), re.IGNORECASE)
            for match in pattern.finditer(text):
                matches.append({
                    'text': match.group(0),
                    'start': match.start(),
                    'end': match.end(),
                    'gazetteer_term': term
                })
        
        results[entity_name] = matches
    
    return results


def detect_text_tables(lines):
    """Detect ASCII/text tables in email body"""
    tables = []
    i = 0
    
    while i < len(lines):
        line = lines[i]
        
        if looks_like_table_header(line):
            if i + 1 < len(lines) and is_table_separator(lines[i + 1]):
                start_line = i
                table_lines = [line, lines[i + 1]]
                
                j = i + 2
                while j < len(lines):
                    data_line = lines[j]
                    if not data_line.strip() or not looks_like_table_row(data_line, line):
                        break
                    table_lines.append(data_line)
                    j += 1
                
                if len(table_lines) > 2:
                    tables.append({
                        'start_line': start_line,
                        'end_line': j - 1,
                        'header_line': start_line,
                        'separator_line': start_line + 1,
                        'data_start': start_line + 2,
                        'lines': table_lines,
                        'header': line
                    })
                    logger.info(f"Detected text table from line {start_line} to {j-1}")
                    i = j
                    continue
        i += 1
    
    return tables


def looks_like_table_header(line):
    """Check if line looks like a table header"""
    if not line.strip():
        return False
    
    parts = re.split(r'\s{2,}|\t+', line.strip())
    if len(parts) < 2:
        return False
    
    common_headers = ['customer', 'amount', 'currency', 'date', 'status', 'id', 'type',
                     'price', 'quantity', 'total', 'name', 'value', 'description']
    
    capital_count = sum(1 for part in parts if part and (part[0].isupper() or part.lower() in common_headers))
    return capital_count >= len(parts) * 0.6


def is_table_separator(line):
    """Check if line is a table separator"""
    if not line.strip():
        return False
    
    stripped = line.strip()
    separator_chars = ['-', '=', '_', '‚îÄ']
    separator_count = sum(1 for char in stripped if char in separator_chars)
    
    return separator_count >= len(stripped) * 0.8 and len(stripped) >= 5


def looks_like_table_row(line, header):
    """Check if line looks like a data row"""
    if not line.strip():
        return False
    
    header_parts = re.split(r'\s{2,}|\t+', header.strip())
    line_parts = re.split(r'\s{2,}|\t+', line.strip())
    
    return abs(len(line_parts) - len(header_parts)) <= 1


def extract_from_text_table(table_info, all_lines, email_data, conversation_id, package_id, activity):
    """Extract data from detected text table"""
    records = []
    header_line = all_lines[table_info['header_line']].strip()
    columns = re.split(r'\s{2,}|\t+', header_line)
    columns = [col.strip() for col in columns if col.strip()]
    
    logger.info(f"Text table columns: {columns}")
    
    for i in range(table_info['data_start'], table_info['end_line'] + 1):
        if i >= len(all_lines):
            break
        
        data_line = all_lines[i].strip()
        if not data_line:
            continue
        
        values = re.split(r'\s{2,}|\t+', data_line)
        values = [val.strip() for val in values if val.strip()]
        
        record = {
            'Trade_ID': email_data.get('trade_id', ''),
            'Email_Date': email_data.get('date', ''),
            'Email_From': email_data.get('sender', ''),
            'Email_Subject': email_data.get('subject', ''),
            'Conversation_ID': conversation_id,
            'Package_ID': package_id,
            'Source_Line': i,
            'Pattern_ID': 'TEXT_TABLE',
            'Line_Index': i,
            'Extraction_Method': 'text_table'
        }
        
        if activity:
            record['ActivityType'] = activity
        
        for col_idx, col_name in enumerate(columns):
            if col_idx < len(values):
                record[col_name] = values[col_idx]
        
        records.append(record)
    
    logger.info(f"Extracted {len(records)} records from text table")
    return records


def extract_from_html_body(email_data, compiled_patterns_map, entity_names):
    """Extract entities from HTML body using patterns"""
    records = []
    body = email_data.get('body', '')
    if not body:
        return records
    
    pattern_matches = extract_with_patterns(body, compiled_patterns_map, entity_names)
    
    for entity_name, matches in pattern_matches.items():
        for match in matches:
            record = {
                'Trade_ID': email_data.get('trade_id', ''),
                'Email_Date': email_data.get('date', ''),
                'Email_From': email_data.get('sender', ''),
                'Email_Subject': email_data.get('subject', ''),
                'Entity': entity_name,
                'Value': match['text'],
                'Pattern_ID': match.get('pattern_id', 'unknown'),
                'Extraction_Method': 'html_pattern'
            }
            records.append(record)
    
    return records


# ============================================================================
# MAIN EXTRACTION WITH THREADING
# ============================================================================

def extract_and_export_threaded(selected_emails, config, progress_queue=None):
    """
    Main extraction function with threading support
    """
    try:
        # Initialize COM in thread
        pythoncom.CoInitialize()
        
        all_records = []
        matched_count = 0
        unseen_count = 0
        conversation_count = 0
        table_count = 0
        
        entity_names = list(config.get('entity_definitions', {}).keys())
        compiled_patterns = compile_patterns(config.get('entity_definitions', {}))
        gazetteer_data = config.get('gazetteer_data', {})
        
        total_emails = len(selected_emails)
        
        for email_idx, email_data in enumerate(selected_emails):
            try:
                # Send progress update
                if progress_queue and email_idx % 5 == 0:
                    progress_queue.put({
                        'type': 'progress',
                        'current': email_idx + 1,
                        'total': total_emails,
                        'message': f"Processing email {email_idx + 1}/{total_emails}"
                    })
                
                # Extract trade ID from subject
                subject = email_data.get('subject', '')
                trade_id_match = re.search(r'([A-Z0-9]{8,})', subject)
                trade_id = trade_id_match.group(1) if trade_id_match else f"EMAIL_{email_idx}"
                email_data['trade_id'] = trade_id
                
                # Split email into lines
                text_body = email_data.get('body', '')
                email_lines = text_body.split('\n')
                
                # Detect conversations
                conversation_id = email_data.get('conversation_id', f'CONV_{email_idx}')
                package_id = f'PKG_{email_idx}_1'
                
                # Detect text tables
                tables = detect_text_tables(email_lines)
                table_count += len(tables)
                
                # Extract from tables
                for table in tables:
                    table_records = extract_from_text_table(
                        table, email_lines, email_data, 
                        conversation_id, package_id, None
                    )
                    all_records.extend(table_records)
                    matched_count += len(table_records)
                
                # Extract from HTML body using patterns
                html_records = extract_from_html_body(email_data, compiled_patterns, entity_names)
                all_records.extend(html_records)
                matched_count += len(html_records)
                
                # Extract using gazetteer
                if gazetteer_data:
                    gazetteer_matches = extract_with_gazetteer(text_body, gazetteer_data, entity_names)
                    for entity_name, matches in gazetteer_matches.items():
                        for match in matches:
                            record = {
                                'Trade_ID': trade_id,
                                'Email_Date': email_data.get('date', ''),
                                'Email_From': email_data.get('sender', ''),
                                'Email_Subject': subject,
                                'Entity': entity_name,
                                'Value': match['text'],
                                'Extraction_Method': 'gazetteer'
                            }
                            all_records.append(record)
                            matched_count += 1
                
                conversation_count += 1
                
            except Exception as e:
                logger.error(f"Error processing email {email_idx}: {str(e)}")
                continue
        
        # Create DataFrame
        if all_records:
            df = pd.DataFrame(all_records)
        else:
            df = pd.DataFrame()
        
        stats = {
            'total_records': len(all_records),
            'matched_count': matched_count,
            'unseen_count': unseen_count,
            'conversation_count': conversation_count,
            'table_count': table_count,
            'emails_processed': total_emails
        }
        
        # Send completion message
        if progress_queue:
            progress_queue.put({
                'type': 'complete',
                'df': df,
                'stats': stats,
                'message': f"Extraction complete! Processed {total_emails} emails"
            })
        
        pythoncom.CoUninitialize()
        return df, stats
    
    except Exception as e:
        logger.error(f"Extraction error: {str(e)}")
        if progress_queue:
            progress_queue.put({
                'type': 'error',
                'message': str(e)
            })
        pythoncom.CoUninitialize()
        return pd.DataFrame(), {}


# ============================================================================
# VISUALIZATION FUNCTIONS (Same as before)
# ============================================================================

def create_extraction_summary_chart(stats):
    """Create summary metrics visualization"""
    fig = go.Figure()
    
    categories = ['Matched', 'Conversations', 'Tables', 'Emails']
    values = [
        stats.get('matched_count', 0),
        stats.get('conversation_count', 0),
        stats.get('table_count', 0),
        stats.get('emails_processed', 0)
    ]
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
    
    fig.add_trace(go.Bar(
        x=categories,
        y=values,
        marker_color=colors,
        text=values,
        textposition='outside'
    ))
    
    fig.update_layout(
        title="Extraction Summary",
        xaxis_title="Category",
        yaxis_title="Count",
        height=400,
        showlegend=False
    )
    
    return fig


def create_entity_distribution_chart(df):
    """Create entity type distribution pie chart"""
    if 'Entity' not in df.columns or df.empty:
        return None
    
    entity_counts = df['Entity'].value_counts()
    
    fig = go.Figure(data=[go.Pie(
        labels=entity_counts.index,
        values=entity_counts.values,
        hole=0.3
    )])
    
    fig.update_layout(
        title="Entity Type Distribution",
        height=400
    )
    
    return fig


def create_extraction_timeline(df):
    """Create timeline of extractions by date"""
    if 'Email_Date' not in df.columns or df.empty:
        return None
    
    df_copy = df.copy()
    df_copy['Date'] = pd.to_datetime(df_copy['Email_Date']).dt.date
    timeline_data = df_copy.groupby('Date').size().reset_index(name='Count')
    
    fig = px.line(
        timeline_data,
        x='Date',
        y='Count',
        title='Extraction Timeline',
        markers=True
    )
    
    fig.update_layout(
        xaxis_title="Date",
        yaxis_title="Number of Extractions",
        height=400
    )
    
    return fig


def create_sender_analysis(df):
    """Create sender-based analysis"""
    if 'Email_From' not in df.columns or df.empty:
        return None
    
    sender_counts = df['Email_From'].value_counts().head(10)
    
    fig = go.Figure(data=[go.Bar(
        x=sender_counts.values,
        y=sender_counts.index,
        orientation='h',
        marker_color='#1f77b4'
    )])
    
    fig.update_layout(
        title="Top 10 Senders by Extractions",
        xaxis_title="Number of Extractions",
        yaxis_title="Sender",
        height=400
    )
    
    return fig


def create_pattern_effectiveness_chart(df):
    """Analyze pattern matching effectiveness"""
    if 'Pattern_ID' not in df.columns or df.empty:
        return None
    
    pattern_counts = df['Pattern_ID'].value_counts().head(10)
    
    fig = go.Figure(data=[go.Bar(
        x=pattern_counts.index,
        y=pattern_counts.values,
        marker_color='#2ca02c'
    )])
    
    fig.update_layout(
        title="Top 10 Pattern Matches",
        xaxis_title="Pattern ID",
        yaxis_title="Match Count",
        height=400
    )
    
    return fig


def create_extraction_method_comparison(df):
    """Compare extraction methods"""
    if 'Extraction_Method' not in df.columns or df.empty:
        return None
    
    method_counts = df['Extraction_Method'].value_counts()
    
    fig = go.Figure(data=[go.Pie(
        labels=method_counts.index,
        values=method_counts.values,
        hole=0.3
    )])
    
    fig.update_layout(
        title="Extraction Method Comparison",
        height=400
    )
    
    return fig


# ============================================================================
# CONFIGURATION & EXPORT FUNCTIONS (Same as before)
# ============================================================================

def load_config_from_file(file_path):
    """Load configuration from JSON file"""
    try:
        with open(file_path, 'r') as f:
            config = json.load(f)
        return config, True
    except Exception as e:
        logger.error(f"Error loading config: {str(e)}")
        return {}, False


def save_config_to_file(config, file_path):
    """Save configuration to JSON file"""
    try:
        with open(file_path, 'w') as f:
            json.dump(config, f, indent=2)
        return True
    except Exception as e:
        logger.error(f"Error saving config: {str(e)}")
        return False


def export_to_csv(df, filename):
    """Export DataFrame to CSV"""
    try:
        output_path = os.path.join(st.session_state.out_path, filename)
        df.to_csv(output_path, index=False)
        return output_path, True
    except Exception as e:
        logger.error(f"Error exporting to CSV: {str(e)}")
        return None, False


def export_to_excel(df, filename, sheet_name='Extractions'):
    """Export DataFrame to Excel"""
    try:
        output_path = os.path.join(st.session_state.out_path, filename)
        df.to_excel(output_path, sheet_name=sheet_name, index=False)
        return output_path, True
    except Exception as e:
        logger.error(f"Error exporting to Excel: {str(e)}")
        return None, False


def create_consolidated_report(df, stats, filename):
    """Create consolidated Excel report with multiple sheets"""
    try:
        output_path = os.path.join(st.session_state.out_path, filename)
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Extractions', index=False)
            
            summary_data = {
                'Metric': list(stats.keys()),
                'Value': list(stats.values())
            }
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='Summary', index=False)
            
            if 'Entity' in df.columns and not df.empty:
                entity_summary = df['Entity'].value_counts().reset_index()
                entity_summary.columns = ['Entity', 'Count']
                entity_summary.to_excel(writer, sheet_name='Entity_Summary', index=False)
            
            if 'Pattern_ID' in df.columns and not df.empty:
                pattern_summary = df['Pattern_ID'].value_counts().reset_index()
                pattern_summary.columns = ['Pattern_ID', 'Count']
                pattern_summary.to_excel(writer, sheet_name='Pattern_Summary', index=False)
        
        return output_path, True
    
    except Exception as e:
        logger.error(f"Error creating consolidated report: {str(e)}")
        return None, False


# ============================================================================
# STREAMLIT UI COMPONENTS
# ============================================================================

def render_sidebar():
    """Render sidebar with configuration options"""
    with st.sidebar:
        st.image("https://img.icons8.com/fluency/96/000000/mail.png", width=80)
        st.title("üìß Email Harvester")
        st.markdown("---")
        
        # Navigation
        page = st.radio(
            "Navigation",
            ["üîå Connect", "üì• Fetch Emails", "üîç Extract", "üìä Visualize", "‚öôÔ∏è Settings"],
            key="nav_radio"
        )
        
        st.markdown("---")
        
        # Connection status
        if st.session_state.connected:
            st.success("‚úÖ Connected to Outlook")
            if st.session_state.selected_mailbox:
                st.info(f"üì¨ Mailbox: {st.session_state.selected_mailbox['name']}")
        else:
            st.warning("‚ö†Ô∏è Not connected")
        
        # Quick stats
        if st.session_state.extraction_df is not None and not st.session_state.extraction_df.empty:
            st.markdown("### üìà Quick Stats")
            st.metric("Total Extractions", len(st.session_state.extraction_df))
            st.metric("Matched Patterns", st.session_state.matched_count)
            st.metric("Conversations", st.session_state.conversation_count)
        
        st.markdown("---")
        st.caption("¬© 2025 Email Harvester Pro (MAPI)")
        
        return page


def render_connect_page():
    """Render Outlook/MAPI connection page"""
    st.markdown('<h1 class="main-header">üîå Connect to Outlook (MAPI)</h1>', unsafe_allow_html=True)
    
    if not MAPI_AVAILABLE:
        st.error("‚ùå MAPI library not available. Please install pywin32: `pip install pywin32`")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### Outlook Configuration")
        
        st.info("""
        **MAPI Connection:**
        - Connects to local Outlook installation
        - No credentials needed (uses Windows authentication)
        - Outlook must be configured and running
        """)
        
        st.markdown("---")
        
        col_a, col_b = st.columns(2)
        
        with col_a:
            if st.button("üîå Connect to Outlook", use_container_width=True, type="primary"):
                with st.spinner("Connecting to Outlook..."):
                    outlook, mapi, mailboxes, success = connect_to_outlook()
                    
                    if success:
                        st.session_state.outlook = outlook
                        st.session_state.mapi = mapi
                        st.session_state.mailboxes = mailboxes
                        st.session_state.connected = True
                        st.success(f"‚úÖ Successfully connected! Found {len(mailboxes)} mailbox(es)")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("‚ùå Connection failed. Ensure Outlook is installed and configured.")
        
        with col_b:
            if st.button("üîÑ Disconnect", use_container_width=True, disabled=not st.session_state.connected):
                st.session_state.outlook = None
                st.session_state.mapi = None
                st.session_state.mailboxes = []
                st.session_state.connected = False
                st.session_state.selected_mailbox = None
                st.session_state.folders = []
                st.success("Disconnected from Outlook")
                st.rerun()
        
        # Display mailboxes if connected
        if st.session_state.connected and st.session_state.mailboxes:
            st.markdown("---")
            st.markdown("### üì¨ Available Mailboxes")
            
            mailbox_names = [mb['name'] for mb in st.session_state.mailboxes]
            selected_mailbox_name = st.selectbox(
                "Select Mailbox",
                mailbox_names,
                key="mailbox_select"
            )
            
            if st.button("Load Mailbox", use_container_width=True):
                selected_mb = next(mb for mb in st.session_state.mailboxes if mb['name'] == selected_mailbox_name)
                st.session_state.selected_mailbox = selected_mb
                
                with st.spinner("Loading folders..."):
                    folders = get_folder_list(selected_mb['folder_obj'])
                    st.session_state.folders = folders
                    st.success(f"‚úÖ Loaded {len(folders)} folder(s)")
                    st.rerun()
    
    with col2:
        st.markdown("### üìù Instructions")
        st.info("""
        1. Ensure Outlook is installed
        2. Configure at least one email account
        3. Click "Connect to Outlook"
        4. Select mailbox
        5. Load folders
        
        **Note:** Uses Windows authentication
        """)
        
        if st.session_state.connected:
            st.success(f"""
            ‚úÖ **Connected!**
            
            Mailboxes: {len(st.session_state.mailboxes)}
            
            Ready to fetch emails!
            """)


def render_fetch_emails_page():
    """Render email fetching page with MAPI"""
    st.markdown('<h1 class="main-header">üì• Fetch Emails (MAPI)</h1>', unsafe_allow_html=True)
    
    if not st.session_state.connected:
        st.warning("‚ö†Ô∏è Please connect to Outlook first (Connect tab)")
        return
    
    if not st.session_state.selected_mailbox:
        st.warning("‚ö†Ô∏è Please select a mailbox first (Connect tab)")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### Fetch Configuration")
        
        st.info(f"**Current Mailbox:** {st.session_state.selected_mailbox['name']}")
        
        # Folder selection
        if st.session_state.folders:
            folder_paths = [f['path'] for f in st.session_state.folders]
            selected_folder_path = st.selectbox(
                "Select Folder",
                folder_paths,
                key="folder_select"
            )
            
            selected_folder = next(f for f in st.session_state.folders if f['path'] == selected_folder_path)
            st.session_state.selected_folder = selected_folder
        else:
            st.warning("No folders loaded. Please load mailbox from Connect tab.")
            return
        
        # Date range
        col_date1, col_date2 = st.columns(2)
        with col_date1:
            start_date = st.date_input(
                "Start Date",
                value=datetime.now() - timedelta(days=7),
                key="start_date_input"
            )
        with col_date2:
            end_date = st.date_input(
                "End Date",
                value=datetime.now(),
                key="end_date_input"
            )
        
        max_emails = st.number_input(
            "Maximum Emails to Fetch",
            min_value=1,
            max_value=10000,
            value=100,
            key="max_emails_input"
        )
        
        st.markdown("---")
        
        if st.button("üì• Fetch Emails", use_container_width=True, type="primary"):
            progress_placeholder = st.empty()
            status_placeholder = st.empty()
            
            # Create progress queue
            progress_queue = Queue()
            
            # Start fetch in thread
            fetch_thread = threading.Thread(
                target=fetch_emails_mapi,
                args=(
                    st.session_state.selected_folder['folder_obj'],
                    start_date,
                    end_date,
                    max_emails,
                    progress_queue
                )
            )
            fetch_thread.start()
            
            # Monitor progress
            while fetch_thread.is_alive() or not progress_queue.empty():
                try:
                    message = progress_queue.get(timeout=0.1)
                    
                    if message['type'] == 'progress':
                        progress = message['current'] / message['total']
                        progress_placeholder.progress(progress)
                        status_placeholder.text(message['message'])
                    
                    elif message['type'] == 'complete':
                        emails = message['emails']
                        st.session_state.emails = emails
                        
                        # Create DataFrame for display
                        email_display_data = []
                        for idx, email in enumerate(emails):
                            email_display_data.append({
                                'Index': idx,
                                'Date': email['date'].strftime('%Y-%m-%d %H:%M') if isinstance(email['date'], datetime) else str(email['date']),
                                'From': email['sender'],
                                'Subject': email['subject'][:50] + '...' if len(email['subject']) > 50 else email['subject'],
                                'Has Attachments': 'üìé' if email['has_attachments'] else '',
                                'Size (KB)': round(email['size'] / 1024, 1)
                            })
                        
                        st.session_state.email_df = pd.DataFrame(email_display_data)
                        progress_placeholder.progress(1.0)
                        status_placeholder.success(message['message'])
                        time.sleep(1)
                        st.rerun()
                    
                    elif message['type'] == 'error':
                        status_placeholder.error(f"‚ùå Error: {message['message']}")
                        break
                
                except:
                    time.sleep(0.1)
                    continue
            
            fetch_thread.join()
    
    with col2:
        st.markdown("### üìä Fetch Statistics")
        if st.session_state.emails:
            st.metric("Total Emails Fetched", len(st.session_state.emails))
            
            with_attachments = sum(1 for e in st.session_state.emails if e['has_attachments'])
            st.metric("With Attachments", with_attachments)
            
            unique_senders = len(set(e['sender'] for e in st.session_state.emails))
            st.metric("Unique Senders", unique_senders)
        else:
            st.info("No emails fetched yet")
    
    # Display fetched emails with multi-select
    if not st.session_state.email_df.empty:
        st.markdown("---")
        st.markdown("### üìß Fetched Emails")
        
        st.markdown("**Select emails to extract:**")
        
        col_select1, col_select2, col_select3 = st.columns(3)
        with col_select1:
            if st.button("‚úÖ Select All", use_container_width=True):
                st.session_state.selected_emails = list(range(len(st.session_state.emails)))
                st.rerun()
        with col_select2:
            if st.button("‚ùå Clear Selection", use_container_width=True):
                st.session_state.selected_emails = []
                st.rerun()
        with col_select3:
            st.info(f"Selected: {len(st.session_state.selected_emails)} emails")
        
        # Display with checkboxes
        for idx, row in st.session_state.email_df.iterrows():
            col_check, col_content = st.columns([1, 20])
            
            with col_check:
                is_selected = idx in st.session_state.selected_emails
                if st.checkbox("", value=is_selected, key=f"email_check_{idx}"):
                    if idx not in st.session_state.selected_emails:
                        st.session_state.selected_emails.append(idx)
                else:
                    if idx in st.session_state.selected_emails:
                        st.session_state.selected_emails.remove(idx)
            
            with col_content:
                with st.expander(f"üìß {row['Subject']} - {row['From']} ({row['Date']})"):
                    email = st.session_state.emails[idx]
                    st.write(f"**From:** {email['sender']} ({email['sender_name']})")
                    st.write(f"**Date:** {email['date']}")
                    st.write(f"**Subject:** {email['subject']}")
                    st.write(f"**Size:** {round(email['size']/1024, 1)} KB")
                    st.write("**Body Preview:**")
                    body_preview = email['body'][:500]
                    st.text_area("", body_preview, height=150, key=f"body_preview_{idx}", disabled=True)


def render_extract_page():
    """Render extraction page with threading"""
    st.markdown('<h1 class="main-header">üîç Extract Entities</h1>', unsafe_allow_html=True)
    
    if not st.session_state.selected_emails:
        st.warning("‚ö†Ô∏è Please select emails to extract from (Fetch Emails tab)")
        return
    
    st.info(f"üìß {len(st.session_state.selected_emails)} emails selected for extraction")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown("### Configuration")
        
        config_option = st.radio(
            "Configuration Source",
            ["Upload Config File", "Use Session Config", "Create New"],
            key="config_option"
        )
        
        if config_option == "Upload Config File":
            uploaded_file = st.file_uploader("Upload JSON Configuration", type=['json'])
            if uploaded_file:
                config_data = json.load(uploaded_file)
                st.session_state.config = config_data
                st.success("‚úÖ Configuration loaded")
        
        elif config_option == "Create New":
            st.markdown("#### Entity Definitions")
            entity_json = st.text_area(
                "Paste entity definitions JSON",
                height=200,
                value=json.dumps(st.session_state.config.get('entity_definitions', {}), indent=2)
            )
            try:
                entity_defs = json.loads(entity_json)
                st.session_state.config['entity_definitions'] = entity_defs
            except:
                st.error("Invalid JSON format")
        
        if st.session_state.config.get('entity_definitions'):
            with st.expander("üìã Current Configuration Summary"):
                entity_defs = st.session_state.config['entity_definitions']
                st.write(f"**Entities Configured:** {len(entity_defs)}")
                for entity_name in entity_defs.keys():
                    st.write(f"- {entity_name}")
    
    with col2:
        st.markdown("### Actions")
        
        if st.button("üîç Start Extraction", use_container_width=True, type="primary"):
            if not st.session_state.config.get('entity_definitions'):
                st.error("Please configure entity definitions first")
            else:
                # Get selected emails
                selected_email_data = [st.session_state.emails[idx] for idx in st.session_state.selected_emails]
                
                progress_placeholder = st.empty()
                status_placeholder = st.empty()
                
                # Create progress queue
                progress_queue = Queue()
                
                # Start extraction in thread
                extract_thread = threading.Thread(
                    target=extract_and_export_threaded,
                    args=(
                        selected_email_data,
                        st.session_state.config,
                        progress_queue
                    )
                )
                extract_thread.start()
                
                # Monitor progress
                start_time = time.time()
                while extract_thread.is_alive() or not progress_queue.empty():
                    try:
                        message = progress_queue.get(timeout=0.1)
                        
                        if message['type'] == 'progress':
                            progress = message['current'] / message['total']
                            progress_placeholder.progress(progress)
                            status_placeholder.text(message['message'])
                        
                        elif message['type'] == 'complete':
                            df = message['df']
                            stats = message['stats']
                            
                            st.session_state.extraction_df = df
                            st.session_state.extraction_results = df.to_dict('records') if not df.empty else []
                            st.session_state.matched_count = stats['matched_count']
                            st.session_state.unseen_count = stats['unseen_count']
                            st.session_state.conversation_count = stats['conversation_count']
                            st.session_state.table_count = stats['table_count']
                            
                            end_time = time.time()
                            elapsed = end_time - start_time
                            
                            progress_placeholder.progress(1.0)
                            status_placeholder.success(f"""
                            ‚úÖ **Extraction Complete!**
                            
                            - **Time:** {elapsed:.2f}s
                            - **Emails:** {stats['emails_processed']}
                            - **Records:** {stats['total_records']}
                            - **Matched:** {stats['matched_count']}
                            - **Conversations:** {stats['conversation_count']}
                            - **Tables:** {stats['table_count']}
                            """)
                            time.sleep(2)
                            st.rerun()
                        
                        elif message['type'] == 'error':
                            status_placeholder.error(f"‚ùå Error: {message['message']}")
                            break
                    
                    except:
                        time.sleep(0.1)
                        continue
                
                extract_thread.join()
        
        st.markdown("---")
        
        if st.button("üíæ Save Config", use_container_width=True):
            filename = f"config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(st.session_state.out_path, filename)
            success = save_config_to_file(st.session_state.config, filepath)
            if success:
                st.success(f"Config saved: {filename}")
        
        if st.button("üóëÔ∏è Clear Results", use_container_width=True):
            st.session_state.extraction_df = pd.DataFrame()
            st.session_state.extraction_results = []
            st.session_state.matched_count = 0
            st.success("Results cleared")
            st.rerun()
    
    # Display results
    if not st.session_state.extraction_df.empty:
        st.markdown("---")
        st.markdown("### üìä Extraction Results")
        
        col_m1, col_m2, col_m3, col_m4 = st.columns(4)
        col_m1.metric("Total Records", len(st.session_state.extraction_df))
        col_m2.metric("Matched", st.session_state.matched_count)
        col_m3.metric("Conversations", st.session_state.conversation_count)
        col_m4.metric("Tables", st.session_state.table_count)
        
        st.dataframe(st.session_state.extraction_df, use_container_width=True, height=400)
        
        st.markdown("### üíæ Export Options")
        col_e1, col_e2, col_e3 = st.columns(3)
        
        with col_e1:
            if st.button("üìÑ Export CSV", use_container_width=True):
                filename = f"extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                filepath, success = export_to_csv(st.session_state.extraction_df, filename)
                if success:
                    with open(filepath, 'rb') as f:
                        st.download_button(
                            "‚¨áÔ∏è Download CSV",
                            f,
                            file_name=filename,
                            mime="text/csv",
                            use_container_width=True
                        )
        
        with col_e2:
            if st.button("üìä Export Excel", use_container_width=True):
                filename = f"extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                filepath, success = export_to_excel(st.session_state.extraction_df, filename)
                if success:
                    with open(filepath, 'rb') as f:
                        st.download_button(
                            "‚¨áÔ∏è Download Excel",
                            f,
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
        
        with col_e3:
            if st.button("üìã Consolidated Report", use_container_width=True):
                filename = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                stats = {
                    'total_records': len(st.session_state.extraction_df),
                    'matched_count': st.session_state.matched_count,
                    'unseen_count': st.session_state.unseen_count,
                    'conversation_count': st.session_state.conversation_count,
                    'table_count': st.session_state.table_count
                }
                filepath, success = create_consolidated_report(
                    st.session_state.extraction_df, stats, filename
                )
                if success:
                    with open(filepath, 'rb') as f:
                        st.download_button(
                            "‚¨áÔ∏è Download Report",
                            f,
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )


def render_visualize_page():
    """Render visualization page"""
    st.markdown('<h1 class="main-header">üìä Visualizations & Analytics</h1>', unsafe_allow_html=True)
    
    if st.session_state.extraction_df.empty:
        st.warning("‚ö†Ô∏è No extraction data available. Please run extraction first.")
        return
    
    df = st.session_state.extraction_df
    
    # Summary statistics
    st.markdown("### üìà Summary Statistics")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    col1.metric("Total Records", len(df))
    col2.metric("Matched Patterns", st.session_state.matched_count)
    col3.metric("Conversations", st.session_state.conversation_count)
    col4.metric("Tables Found", st.session_state.table_count)
    
    if 'Entity' in df.columns:
        unique_entities = df['Entity'].nunique()
        col5.metric("Unique Entities", unique_entities)
    
    st.markdown("---")
    
    # Visualization tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Overview",
        "üéØ Entity Analysis",
        "üìÖ Timeline",
        "üë• Sender Analysis",
        "üîç Pattern Analysis"
    ])
    
    with tab1:
        st.markdown("### Extraction Overview")
        
        col_v1, col_v2 = st.columns(2)
        
        with col_v1:
            stats = {
                'matched_count': st.session_state.matched_count,
                'conversation_count': st.session_state.conversation_count,
                'table_count': st.session_state.table_count,
                'emails_processed': len(st.session_state.selected_emails)
            }
            fig = create_extraction_summary_chart(stats)
            st.plotly_chart(fig, use_container_width=True)
        
        with col_v2:
            fig = create_extraction_method_comparison(df)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("Extraction method data not available")
    
    with tab2:
        st.markdown("### Entity Type Analysis")
        
        if 'Entity' in df.columns:
            col_e1, col_e2 = st.columns(2)
            
            with col_e1:
                fig = create_entity_distribution_chart(df)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
            
            with col_e2:
                st.markdown("#### Entity Counts")
                entity_counts = df['Entity'].value_counts().reset_index()
                entity_counts.columns = ['Entity', 'Count']
                st.dataframe(entity_counts, use_container_width=True, height=400)
            
            if 'Value' in df.columns:
                st.markdown("#### Sample Entity Values")
                selected_entity = st.selectbox(
                    "Select Entity Type",
                    df['Entity'].unique()
                )
                
                filtered_df = df[df['Entity'] == selected_entity][['Entity', 'Value', 'Email_Subject']].head(20)
                st.dataframe(filtered_df, use_container_width=True)
        else:
            st.info("Entity data not available")
    
    with tab3:
        st.markdown("### Timeline Analysis")
        
        if 'Email_Date' in df.columns:
            fig = create_extraction_timeline(df)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("#### Hourly Distribution")
            df_copy = df.copy()
            df_copy['Hour'] = pd.to_datetime(df_copy['Email_Date']).dt.hour
            hourly_dist = df_copy['Hour'].value_counts().sort_index()
            
            fig_hourly = px.bar(
                x=hourly_dist.index,
                y=hourly_dist.values,
                labels={'x': 'Hour of Day', 'y': 'Count'},
                title='Extractions by Hour of Day'
            )
            st.plotly_chart(fig_hourly, use_container_width=True)
        else:
            st.info("Date information not available")
    
    with tab4:
        st.markdown("### Sender Analysis")
        
        if 'Email_From' in df.columns:
            col_s1, col_s2 = st.columns(2)
            
            with col_s1:
                fig = create_sender_analysis(df)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
            
            with col_s2:
                st.markdown("#### Sender Statistics")
                sender_stats = df.groupby('Email_From').agg({
                    'Email_Subject': 'count',
                    'Trade_ID': 'nunique'
                }).reset_index()
                sender_stats.columns = ['Sender', 'Total Extractions', 'Unique Trades']
                sender_stats = sender_stats.sort_values('Total Extractions', ascending=False).head(10)
                st.dataframe(sender_stats, use_container_width=True)
        else:
            st.info("Sender information not available")
    
    with tab5:
        st.markdown("### Pattern Effectiveness Analysis")
        
        if 'Pattern_ID' in df.columns:
            col_p1, col_p2 = st.columns(2)
            
            with col_p1:
                fig = create_pattern_effectiveness_chart(df)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
            
            with col_p2:
                st.markdown("#### Pattern Statistics")
                pattern_stats = df['Pattern_ID'].value_counts().reset_index()
                pattern_stats.columns = ['Pattern ID', 'Match Count']
                st.dataframe(pattern_stats, use_container_width=True, height=400)
            
            if 'Entity' in df.columns:
                st.markdown("#### Pattern Performance by Entity")
                pattern_entity = df.groupby(['Entity', 'Pattern_ID']).size().reset_index(name='Count')
                fig_heatmap = px.density_heatmap(
                    pattern_entity,
                    x='Pattern_ID',
                    y='Entity',
                    z='Count',
                    title='Pattern Matches by Entity Type'
                )
                st.plotly_chart(fig_heatmap, use_container_width=True)
        else:
            st.info("Pattern information not available")


def render_settings_page():
    """Render settings page"""
    st.markdown('<h1 class="main-header">‚öôÔ∏è Settings & Configuration</h1>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["üìÅ Paths", "üîß Configuration", "‚ÑπÔ∏è About"])
    
    with tab1:
        st.markdown("### Directory Configuration")
        
        temp_path = st.text_input(
            "Temporary Files Path",
            value=st.session_state.temp_path,
            key="temp_path_input"
        )
        
        out_path = st.text_input(
            "Output Files Path",
            value=st.session_state.out_path,
            key="out_path_input"
        )
        
        if st.button("üíæ Update Paths"):
            st.session_state.temp_path = temp_path
            st.session_state.out_path = out_path
            
            os.makedirs(temp_path, exist_ok=True)
            os.makedirs(out_path, exist_ok=True)
            
            st.success("Paths updated successfully!")
        
        st.markdown("---")
        st.markdown("### Directory Info")
        
        col_d1, col_d2 = st.columns(2)
        
        with col_d1:
            st.info(f"""
            **Temp Path:**
            `{st.session_state.temp_path}`
            
            **Exists:** {os.path.exists(st.session_state.temp_path)}
            """)
        
        with col_d2:
            st.info(f"""
            **Output Path:**
            `{st.session_state.out_path}`
            
            **Exists:** {os.path.exists(st.session_state.out_path)}
            """)
    
    with tab2:
        st.markdown("### Application Configuration")
        
        st.markdown("#### Entity Definitions")
        entity_json_str = json.dumps(st.session_state.config.get('entity_definitions', {}), indent=2)
        entity_json = st.text_area(
            "Entity Definitions (JSON)",
            value=entity_json_str,
            height=300
        )
        
        col_c1, col_c2 = st.columns(2)
        
        with col_c1:
            if st.button("üíæ Save Configuration"):
                try:
                    entity_defs = json.loads(entity_json)
                    st.session_state.config['entity_definitions'] = entity_defs
                    st.success("Configuration saved!")
                except Exception as e:
                    st.error(f"Invalid JSON: {str(e)}")
        
        with col_c2:
            if st.button("üì• Export Configuration"):
                filename = f"config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                config_str = json.dumps(st.session_state.config, indent=2)
                st.download_button(
                    "‚¨áÔ∏è Download Config",
                    config_str,
                    file_name=filename,
                    mime="application/json"
                )
        
        st.markdown("---")
        
        st.markdown("#### Import Configuration")
        uploaded_config = st.file_uploader("Upload Configuration File", type=['json'])
        if uploaded_config:
            try:
                config_data = json.load(uploaded_config)
                st.session_state.config = config_data
                st.success("Configuration imported successfully!")
                st.json(config_data)
            except Exception as e:
                st.error(f"Error loading configuration: {str(e)}")
    
    with tab3:
        st.markdown("### About Email Harvester Pro")
        
        st.info("""
        **Email Harvester Pro** - Streamlit Version with MAPI
        
        **Features:**
        - üìß MAPI/Outlook integration
        - üì¨ Multiple mailbox support
        - üìÅ Folder navigation
        - üîç Advanced pattern matching
        - üìä Interactive visualizations
        - üíæ Multiple export formats
        - üßµ Threading support
        
        **Technology Stack:**
        - Streamlit (Web UI)
        - MAPI/win32com (Email access)
        - Pandas (Data processing)
        - Plotly (Visualizations)
        - Threading (Async operations)
        
        **Version:** 2.0.0 (MAPI Edition)
        """)
        
        st.markdown("---")
        st.markdown("### System Information")
        
        col_i1, col_i2 = st.columns(2)
        
        with col_i1:
            st.metric("Python Version", f"{os.sys.version_info.major}.{os.sys.version_info.minor}")
            st.metric("MAPI Available", "‚úÖ" if MAPI_AVAILABLE else "‚ùå")
        
        with col_i2:
            st.metric("Total Emails Fetched", len(st.session_state.emails))
            st.metric("Total Extractions", len(st.session_state.extraction_df) if not st.session_state.extraction_df.empty else 0)


# ============================================================================
# MAIN APPLICATION
# ============================================================================

def main():
    """Main application entry point"""
    
    # Initialize session state
    init_session_state()
    
    # Render sidebar and get current page
    current_page = render_sidebar()
    
    # Render appropriate page
    if current_page == "üîå Connect":
        render_connect_page()
    
    elif current_page == "üì• Fetch Emails":
        render_fetch_emails_page()
    
    elif current_page == "üîç Extract":
        render_extract_page()
    
    elif current_page == "üìä Visualize":
        render_visualize_page()
    
    elif current_page == "‚öôÔ∏è Settings":
        render_settings_page()


if __name__ == "__main__":
    main()
